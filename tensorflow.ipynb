{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65dbdd80",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-08-01T15:27:56.777922Z",
     "iopub.status.busy": "2022-08-01T15:27:56.777458Z",
     "iopub.status.idle": "2022-08-01T15:28:04.635953Z",
     "shell.execute_reply": "2022-08-01T15:28:04.634958Z"
    },
    "papermill": {
     "duration": 7.87189,
     "end_time": "2022-08-01T15:28:04.638677",
     "exception": false,
     "start_time": "2022-08-01T15:27:56.766787",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers as L\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14a1c64b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T15:28:04.657569Z",
     "iopub.status.busy": "2022-08-01T15:28:04.656410Z",
     "iopub.status.idle": "2022-08-01T15:28:04.731654Z",
     "shell.execute_reply": "2022-08-01T15:28:04.730771Z"
    },
    "papermill": {
     "duration": 0.087249,
     "end_time": "2022-08-01T15:28:04.734234",
     "exception": false,
     "start_time": "2022-08-01T15:28:04.646985",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAIN_TRANSACTIONS_PATH = '../input/alfabattle2-sandbox/alfabattle2_sand_alfabattle2_train_transactions_contest/train_transactions_contest'\n",
    "TEST_TRANSACTIONS_PATH = '../input/alfabattle2-sandbox/alfabattle2_sand_alfabattle2_test_transactions_contest/test_transactions_contest'\n",
    "\n",
    "TRAIN_TARGET_PATH = '../input/alfabattle2-sandbox/alfabattle2_sand_alfabattle2_train_target.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7b52013",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T15:28:04.756253Z",
     "iopub.status.busy": "2022-08-01T15:28:04.755916Z",
     "iopub.status.idle": "2022-08-01T15:28:05.163375Z",
     "shell.execute_reply": "2022-08-01T15:28:05.162373Z"
    },
    "papermill": {
     "duration": 0.420897,
     "end_time": "2022-08-01T15:28:05.165834",
     "exception": false,
     "start_time": "2022-08-01T15:28:04.744937",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_frame = pd.read_csv(TRAIN_TARGET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a56d70a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T15:28:05.184170Z",
     "iopub.status.busy": "2022-08-01T15:28:05.183277Z",
     "iopub.status.idle": "2022-08-01T15:28:05.257371Z",
     "shell.execute_reply": "2022-08-01T15:28:05.255863Z"
    },
    "papermill": {
     "duration": 0.085435,
     "end_time": "2022-08-01T15:28:05.259482",
     "exception": false,
     "start_time": "2022-08-01T15:28:05.174047",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_parquet_dataset_from_local(path_to_dataset: str, start_from: int = 0,\n",
    "                                     num_parts_to_read: int = 2, columns=None, verbose=False) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    читает num_parts_to_read партиций, преобразует их к pd.DataFrame и возвращает\n",
    "    :param path_to_dataset: путь до директории с партициями\n",
    "    :param start_from: номер партиции, с которой начать чтение\n",
    "    :param num_parts_to_read: количество партиций, которые требуется прочитать\n",
    "    :param columns: список колонок, которые нужно прочитать из партиции\n",
    "    :return: pd.DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    res = []\n",
    "    dataset_paths = sorted([os.path.join(path_to_dataset, filename) for filename in os.listdir(path_to_dataset) \n",
    "                              if filename.startswith('part')])\n",
    "    \n",
    "    start_from = max(0, start_from)\n",
    "    chunks = dataset_paths[start_from: start_from + num_parts_to_read]\n",
    "    if verbose:\n",
    "        print('Reading chunks:\\n')\n",
    "        for chunk in chunks:\n",
    "            print(chunk)\n",
    "    for chunk_path in tqdm_notebook(chunks, desc=\"Reading dataset with pandas\"):\n",
    "        chunk = pd.read_parquet(chunk_path,columns=columns)\n",
    "        res.append(chunk)\n",
    "    return pd.concat(res).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a74af35e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T15:28:05.278434Z",
     "iopub.status.busy": "2022-08-01T15:28:05.277012Z",
     "iopub.status.idle": "2022-08-01T15:28:05.346408Z",
     "shell.execute_reply": "2022-08-01T15:28:05.345571Z"
    },
    "papermill": {
     "duration": 0.080735,
     "end_time": "2022-08-01T15:28:05.348536",
     "exception": false,
     "start_time": "2022-08-01T15:28:05.267801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "features = ['currency', 'operation_kind', 'card_type', 'operation_type', 'operation_type_group', 'ecommerce_flag',\n",
    "            'payment_system', 'income_flag', 'mcc', 'country', 'city', 'mcc_category', 'day_of_week',\n",
    "            'hour', 'weekofyear', 'amnt', 'days_before', 'hour_diff']\n",
    "\n",
    "def pad_sequence(array, max_len) -> np.array:\n",
    "    \"\"\"\n",
    "    принимает список списков (array) и делает padding каждого вложенного списка до max_len\n",
    "    :param array: список списков\n",
    "    :param max_len: максимальная длина до которой нужно сделать padding\n",
    "    :return: np.array после padding каждого вложенного списка до одинаковой длины\n",
    "    \"\"\"\n",
    "    add_zeros = max_len - len(array[0])\n",
    "    return np.array([list(x) + [0] * add_zeros for x in array])\n",
    "\n",
    "\n",
    "def truncate(x, num_last_transactions=750):\n",
    "    return x.values.transpose()[:, -num_last_transactions:].tolist()\n",
    "\n",
    "\n",
    "def transform_transactions_to_sequences(transactions_frame: pd.DataFrame,\n",
    "                                        num_last_transactions=750) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    принимает frame с транзакциями клиентов, сортирует транзакции по клиентам\n",
    "    (внутри клиента сортирует транзакции по возрастанию), берет num_last_transactions танзакций,\n",
    "    возвращает новый pd.DataFrame с двумя колонками: app_id и sequences.\n",
    "    каждое значение в колонке sequences - это список списков.\n",
    "    каждый список - значение одного конкретного признака во всех клиентских транзакциях.\n",
    "    Всего признаков len(features), поэтому будет len(features) списков.\n",
    "    Данная функция крайне полезна для подготовки датасета для работы с нейронными сетями.\n",
    "    :param transactions_frame: фрейм с транзакциями клиентов\n",
    "    :param num_last_transactions: количество транзакций клиента, которые будут рассмотрены\n",
    "    :return: pd.DataFrame из двух колонок (app_id, sequences)\n",
    "    \"\"\"\n",
    "    return transactions_frame \\\n",
    "        .sort_values(['app_id', 'transaction_number']) \\\n",
    "        .groupby(['app_id'])[features] \\\n",
    "        .apply(lambda x: truncate(x, num_last_transactions=num_last_transactions)) \\\n",
    "        .reset_index().rename(columns={0: 'sequences'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f9d0353",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T15:28:05.365755Z",
     "iopub.status.busy": "2022-08-01T15:28:05.365463Z",
     "iopub.status.idle": "2022-08-01T15:28:05.434863Z",
     "shell.execute_reply": "2022-08-01T15:28:05.434028Z"
    },
    "papermill": {
     "duration": 0.080325,
     "end_time": "2022-08-01T15:28:05.436952",
     "exception": false,
     "start_time": "2022-08-01T15:28:05.356627",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_padded_buckets(frame_of_sequences: pd.DataFrame, bucket_info: Dict[int, int],\n",
    "                          save_to_file_path=None, has_target=True):\n",
    "    \"\"\"\n",
    "    Функция реализует sequence_bucketing технику для обучения нейронных сетей.\n",
    "    Принимает на вход frame_of_sequences (результат работы функции transform_transactions_to_sequences),\n",
    "    словарь bucket_info, где для последовательности каждой длины указано, до какой максимальной длины нужно делать\n",
    "    padding, далее группирует транзакции по бакетам (на основе длины), делает padding транзакций и сохраняет результат\n",
    "    в pickle файл, если нужно\n",
    "    :param frame_of_sequences: pd.DataFrame c транзакциями (результат применения transform_transactions_to_sequences)\n",
    "    :param bucket_info: словарь, где для последовательности каждой длины указано, до какой максимальной длины нужно делать\n",
    "    padding\n",
    "    :param save_to_file_path: опциональный путь до файла, куда нужно сохранить результат\n",
    "    :param has_target: флаг, есть ли в frame_of_sequences целевая переменная или нет. Если есть, то\n",
    "    будет записано в результат\n",
    "    :return: возвращает словарь с следюущими ключами (padded_sequences, targets, app_id, products)\n",
    "    \"\"\"\n",
    "    frame_of_sequences['bucket_idx'] = frame_of_sequences.sequence_length.map(bucket_info)\n",
    "    padded_seq = []\n",
    "    targets = []\n",
    "    app_ids = []\n",
    "    products = []\n",
    "\n",
    "    for size, bucket in frame_of_sequences.groupby('bucket_idx'):\n",
    "        padded_sequences = bucket.sequences.apply(lambda x: pad_sequence(x, size)).values\n",
    "        padded_sequences = np.array([np.array(x) for x in padded_sequences])\n",
    "        padded_seq.append(padded_sequences)\n",
    "\n",
    "        if has_target:\n",
    "            targets.append(bucket.flag.values)\n",
    "\n",
    "        app_ids.append(bucket.app_id.values)\n",
    "        products.append(bucket['product'].values)\n",
    "\n",
    "    frame_of_sequences.drop(columns=['bucket_idx'], inplace=True)\n",
    "\n",
    "    dict_result = {\n",
    "        'padded_sequences': np.array(padded_seq, dtype=object),\n",
    "        'targets': np.array(targets, dtype=object) if targets else [],\n",
    "        'app_id': np.array(app_ids, dtype=object),\n",
    "        'products': np.array(products, dtype=object),\n",
    "    }\n",
    "\n",
    "    if save_to_file_path:\n",
    "        with open(save_to_file_path, 'wb') as f:\n",
    "            pickle.dump(dict_result, f)\n",
    "    return dict_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd269a0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T15:28:05.454292Z",
     "iopub.status.busy": "2022-08-01T15:28:05.453451Z",
     "iopub.status.idle": "2022-08-01T15:28:05.546479Z",
     "shell.execute_reply": "2022-08-01T15:28:05.545477Z"
    },
    "papermill": {
     "duration": 0.103838,
     "end_time": "2022-08-01T15:28:05.548662",
     "exception": false,
     "start_time": "2022-08-01T15:28:05.444824",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../input/alfabattle2-sandbox/constants_for_rnn/constants_for_rnn/buckets_info.pkl', 'rb') as f:\n",
    "    mapping_seq_len_to_padded_len = pickle.load(f)\n",
    "    \n",
    "with open('../input/alfabattle2-sandbox/constants_for_rnn/constants_for_rnn/dense_features_buckets.pkl', 'rb') as f:\n",
    "    dense_features_buckets = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b589d3a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T15:28:05.566014Z",
     "iopub.status.busy": "2022-08-01T15:28:05.565323Z",
     "iopub.status.idle": "2022-08-01T15:28:05.632662Z",
     "shell.execute_reply": "2022-08-01T15:28:05.631816Z"
    },
    "papermill": {
     "duration": 0.078191,
     "end_time": "2022-08-01T15:28:05.634769",
     "exception": false,
     "start_time": "2022-08-01T15:28:05.556578",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_buckets_from_transactions(path_to_dataset, save_to_path, frame_with_ids = None, \n",
    "                                     num_parts_to_preprocess_at_once: int = 1, \n",
    "                                     num_parts_total=50, has_target=False):\n",
    "    block = 0\n",
    "    for step in tqdm(range(0, num_parts_total, num_parts_to_preprocess_at_once), \n",
    "                                   desc=\"Transforming transactions data\"):\n",
    "        transactions_frame = read_parquet_dataset_from_local(path_to_dataset, step, num_parts_to_preprocess_at_once, \n",
    "                                                             verbose=True)\n",
    "        for dense_col in ['amnt', 'days_before', 'hour_diff']:\n",
    "            transactions_frame[dense_col] = np.digitize(transactions_frame[dense_col], bins=dense_features_buckets[dense_col])\n",
    "            \n",
    "        seq = transform_transactions_to_sequences(transactions_frame)\n",
    "        seq['sequence_length'] = seq.sequences.apply(lambda x: len(x[1]))\n",
    "        \n",
    "        if frame_with_ids is not None:\n",
    "            seq = seq.merge(frame_with_ids, on='app_id')\n",
    "\n",
    "        block_as_str = str(block)\n",
    "        if len(block_as_str) == 1:\n",
    "            block_as_str = '00' + block_as_str\n",
    "        else:\n",
    "            block_as_str = '0' + block_as_str\n",
    "            how\n",
    "        processed_fragment =  create_padded_buckets(seq, mapping_seq_len_to_padded_len, has_target=has_target, \n",
    "                                                    save_to_file_path=os.path.join(save_to_path, \n",
    "                                                                                   f'processed_chunk_{block_as_str}.pkl'))\n",
    "        block += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8642ac0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T15:28:05.651578Z",
     "iopub.status.busy": "2022-08-01T15:28:05.651308Z",
     "iopub.status.idle": "2022-08-01T15:28:05.749375Z",
     "shell.execute_reply": "2022-08-01T15:28:05.748510Z"
    },
    "papermill": {
     "duration": 0.108867,
     "end_time": "2022-08-01T15:28:05.751433",
     "exception": false,
     "start_time": "2022-08-01T15:28:05.642566",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../input/train-val-buckets/val_buckets/processed_chunk_000.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_001.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_002.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_003.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_004.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_005.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_006.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_007.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_008.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_009.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_010.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_011.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_012.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_013.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_014.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_015.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_016.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_017.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_018.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_019.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_020.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_021.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_022.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_023.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_024.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_025.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_026.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_027.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_028.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_029.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_030.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_031.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_032.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_033.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_034.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_035.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_036.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_037.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_038.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_039.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_040.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_041.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_042.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_043.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_044.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_045.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_046.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_047.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_048.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_049.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_dataset = '../input/train-val-buckets/val_buckets'\n",
    "dir_with_datasets = os.listdir(path_to_dataset)\n",
    "dataset_val = sorted([os.path.join(path_to_dataset, x) for x in dir_with_datasets])\n",
    "dataset_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b46c5d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T15:28:05.769139Z",
     "iopub.status.busy": "2022-08-01T15:28:05.768272Z",
     "iopub.status.idle": "2022-08-01T15:28:05.843450Z",
     "shell.execute_reply": "2022-08-01T15:28:05.842519Z"
    },
    "papermill": {
     "duration": 0.086066,
     "end_time": "2022-08-01T15:28:05.845543",
     "exception": false,
     "start_time": "2022-08-01T15:28:05.759477",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../input/train-val-buckets/train_buckets/processed_chunk_000.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_001.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_002.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_003.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_004.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_005.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_006.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_007.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_008.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_009.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_010.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_011.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_012.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_013.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_014.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_015.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_016.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_017.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_018.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_019.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_020.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_021.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_022.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_023.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_024.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_025.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_026.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_dataset = '../input/train-val-buckets/train_buckets'\n",
    "dir_with_datasets = os.listdir(path_to_dataset)\n",
    "dataset_train = sorted([os.path.join(path_to_dataset, x) for x in dir_with_datasets])\n",
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1cc2235",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T15:28:05.863184Z",
     "iopub.status.busy": "2022-08-01T15:28:05.862554Z",
     "iopub.status.idle": "2022-08-01T15:28:05.984700Z",
     "shell.execute_reply": "2022-08-01T15:28:05.983761Z"
    },
    "papermill": {
     "duration": 0.133108,
     "end_time": "2022-08-01T15:28:05.986802",
     "exception": false,
     "start_time": "2022-08-01T15:28:05.853694",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d8c5a31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T15:28:06.006191Z",
     "iopub.status.busy": "2022-08-01T15:28:06.005911Z",
     "iopub.status.idle": "2022-08-01T15:28:06.082291Z",
     "shell.execute_reply": "2022-08-01T15:28:06.081429Z"
    },
    "papermill": {
     "duration": 0.088284,
     "end_time": "2022-08-01T15:28:06.084316",
     "exception": false,
     "start_time": "2022-08-01T15:28:05.996032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "transaction_features = ['currency', 'operation_kind', 'card_type', 'operation_type',\n",
    "                        'operation_type_group', 'ecommerce_flag', 'payment_system',\n",
    "                        'income_flag', 'mcc', 'country', 'city', 'mcc_category',\n",
    "                        'day_of_week', 'hour', 'weekofyear', 'amnt', 'days_before', 'hour_diff']\n",
    "\n",
    "def batches_generator(list_of_paths, batch_size=32, shuffle=False, is_infinite=False,\n",
    "                      verbose=False, device=None, output_format='tf', is_train=True):\n",
    "    \"\"\"\n",
    "    функция для создания батчей на вход для нейронной сети для моделей на keras и pytorch.\n",
    "    так же может использоваться как функция на стадии инференса\n",
    "    :param list_of_paths: путь до директории с предобработанными последовательностями\n",
    "    :param batch_size: размер батча\n",
    "    :param shuffle: флаг, если True, то перемешивает list_of_paths и так же\n",
    "    перемешивает последовательности внутри файла\n",
    "    :param is_infinite: флаг, если True,  то создает бесконечный генератор батчей\n",
    "    :param verbose: флаг, если True, то печатает текущий обрабатываемый файл\n",
    "    :param device: device на который положить данные, если работа на торче\n",
    "    :param output_format: допустимые варианты ['tf', 'torch']. Если 'torch', то возвращает словарь,\n",
    "    где ключи - батчи из признаков, таргетов и app_id. Если 'tf', то возвращает картеж: лист input-ов\n",
    "    для модели, и список таргетов.\n",
    "    :param is_train: флаг, Если True, то для кераса вернет (X, y), где X - input-ы в модель, а y - таргеты, \n",
    "    если False, то в y будут app_id; для torch вернет словарь с ключами на device.\n",
    "    :return: бачт из последовательностей и таргетов (или app_id)\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        if shuffle:\n",
    "            np.random.shuffle(list_of_paths)\n",
    "\n",
    "        for path in list_of_paths:\n",
    "            if verbose:\n",
    "                print(f'reading {path}')\n",
    "\n",
    "            with open(path, 'rb') as f:\n",
    "                '''\n",
    "                26.pkl is truncated \n",
    "                '''\n",
    "                if path == '../input/train-val-buckets/train_buckets/processed_chunk_026.pkl':\n",
    "                    continue\n",
    "                data = pickle.load(f)\n",
    "            padded_sequences, targets, products = data['padded_sequences'], data['targets'], data[\n",
    "                'products']\n",
    "            app_ids = data['app_id']\n",
    "            indices = np.arange(len(products))\n",
    "\n",
    "            if shuffle:\n",
    "                np.random.shuffle(indices)\n",
    "                padded_sequences = padded_sequences[indices]\n",
    "                targets = targets[indices]\n",
    "                products = products[indices]\n",
    "                app_ids = app_ids[indices]\n",
    "\n",
    "            for idx in range(len(products)):\n",
    "                bucket, product = padded_sequences[idx], products[idx]\n",
    "                app_id = app_ids[idx]\n",
    "                \n",
    "                if is_train:\n",
    "                    target = targets[idx]\n",
    "                \n",
    "                for jdx in range(0, len(bucket), batch_size):\n",
    "                    batch_sequences = bucket[jdx: jdx + batch_size]\n",
    "                    if is_train:\n",
    "                        batch_targets = target[jdx: jdx + batch_size]\n",
    "                    \n",
    "                    batch_products = product[jdx: jdx + batch_size]\n",
    "                    batch_app_ids = app_id[jdx: jdx + batch_size]\n",
    "                    \n",
    "                    if output_format == 'tf':\n",
    "                        batch_sequences = [batch_sequences[:, i] for i in\n",
    "                                           range(len(transaction_features))]\n",
    "                        \n",
    "                        # append product as input to tf model\n",
    "                        batch_sequences.append(batch_products)\n",
    "                        if is_train:\n",
    "                            yield batch_sequences, batch_targets\n",
    "                        else:\n",
    "                             yield batch_sequences, batch_app_ids\n",
    "                    else:\n",
    "                        batch_sequences = [torch.LongTensor(batch_sequences[:, i]).to(device)\n",
    "                                           for i in range(len(transaction_features))]\n",
    "                        if is_train:\n",
    "                            yield dict(transactions_features=batch_sequences,\n",
    "                                       product=torch.LongTensor(batch_products).to(device),\n",
    "                                       label=torch.LongTensor(batch_targets).to(device),\n",
    "                                       app_id=batch_app_ids)\n",
    "                        else:\n",
    "                            yield dict(transactions_features=batch_sequences,\n",
    "                                       product=torch.LongTensor(batch_products).to(device),\n",
    "                                       app_id=batch_app_ids)\n",
    "        if not is_infinite:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19008843",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T15:28:06.102143Z",
     "iopub.status.busy": "2022-08-01T15:28:06.101872Z",
     "iopub.status.idle": "2022-08-01T15:28:06.171199Z",
     "shell.execute_reply": "2022-08-01T15:28:06.170359Z"
    },
    "papermill": {
     "duration": 0.080968,
     "end_time": "2022-08-01T15:28:06.173469",
     "exception": false,
     "start_time": "2022-08-01T15:28:06.092501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation metric doesn't improve after a given patience.\"\"\"\n",
    "\n",
    "    def __init__(self, patience=7, mode='min', verbose=False, delta=0, save_path='checkpoint.hdf5', metric_name=None, save_format='tf'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            mode (str): One of ['min', 'max'], whether to maximize or minimaze the metric.\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            save_path (str): Path to saved model\n",
    "        \"\"\"\n",
    "        if mode not in ['min', 'max']:\n",
    "            raise ValueError(f'Unrecognized mode: {mode}!')\n",
    "\n",
    "        self.patience = patience\n",
    "        self.mode = mode\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.best_prev_score = np.Inf if mode == 'min' else -np.Inf\n",
    "        self.delta = delta\n",
    "        self.save_path = save_path\n",
    "        self.metric_name = 'metric' if not metric_name else metric_name\n",
    "        if save_format not in ['torch', 'tf']:\n",
    "            raise ValueError('Expected to save in one of the following formats: [\"torch\", \"tf\"]')\n",
    "        self.save_format = save_format\n",
    "        \n",
    "    def __call__(self, metric_value, model):\n",
    "\n",
    "        score = -metric_value if self.mode == 'min' else metric_value\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(metric_value, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(\n",
    "                f'No imporvement in Validation {self.metric_name}. Current: {score:.6f}. Current best: {self.best_score:.6f}')\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(metric_value, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, metric_value, model):\n",
    "        \"\"\"Saves model when validation loss decrease.\"\"\"\n",
    "        if self.verbose:\n",
    "            print(\n",
    "                f'Validation {self.metric_name} improved ({self.best_prev_score:.6f} --> {metric_value:.6f}).  Saving model ...')\n",
    "        if self.save_format == 'tf':\n",
    "            model.save_weights(self.save_path)\n",
    "        else:\n",
    "            torch.save(model.state_dict(), self.save_path)\n",
    "            \n",
    "        self.best_prev_score = metric_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465ea2f6",
   "metadata": {
    "papermill": {
     "duration": 0.008248,
     "end_time": "2022-08-01T15:28:06.190528",
     "exception": false,
     "start_time": "2022-08-01T15:28:06.182280",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## TF-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1eae5a6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T15:28:06.209935Z",
     "iopub.status.busy": "2022-08-01T15:28:06.208289Z",
     "iopub.status.idle": "2022-08-01T15:28:06.272249Z",
     "shell.execute_reply": "2022-08-01T15:28:06.271415Z"
    },
    "papermill": {
     "duration": 0.07532,
     "end_time": "2022-08-01T15:28:06.274317",
     "exception": false,
     "start_time": "2022-08-01T15:28:06.198997",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, dataset_train, batch_size=64, shuffle=True, cur_epoch=0,\n",
    "                steps_per_epoch=5000, callbacks=None):\n",
    "    \"\"\"\n",
    "    функция обучения модели одну эпоху\n",
    "    :param model: tf.keras.Model\n",
    "    :param dataset_train: путь до директории с последовательностями\n",
    "    :param batch_size: размер батча\n",
    "    :param shuffle: флаг, если True, то перемешивает данные\n",
    "    :param cur_epoch:\n",
    "    :param steps_per_epoch:\n",
    "    :param callbacks: cписок из tf.keras.callbacks или None\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    train_generator = batches_generator(dataset_train, batch_size=batch_size, shuffle=shuffle,\n",
    "                                        output_format='tf', is_train=True)\n",
    "    model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=cur_epoch + 1,\n",
    "              initial_epoch=cur_epoch, callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "085ae236",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T15:28:06.293194Z",
     "iopub.status.busy": "2022-08-01T15:28:06.292927Z",
     "iopub.status.idle": "2022-08-01T15:28:06.354040Z",
     "shell.execute_reply": "2022-08-01T15:28:06.353195Z"
    },
    "papermill": {
     "duration": 0.07243,
     "end_time": "2022-08-01T15:28:06.356133",
     "exception": false,
     "start_time": "2022-08-01T15:28:06.283703",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval_model(model, dataset_val, batch_size=32) -> float:\n",
    "    \"\"\"\n",
    "    функция для оценки качества модели на отложенной выборке, возвращает roc-auc на валидационной\n",
    "    выборке\n",
    "    :param model: tf.keras.Model\n",
    "    :param dataset_val: путь до директории с последовательностями\n",
    "    :param batch_size: размер батча\n",
    "    :return: val roc-auc score\n",
    "    \"\"\"\n",
    "    val_generator = batches_generator(dataset_val, batch_size=batch_size, shuffle=False,\n",
    "                                      output_format='tf', is_train=True)\n",
    "    preds = model.predict(val_generator).flatten()\n",
    "    val_generator = batches_generator(dataset_val, batch_size=batch_size, shuffle=False,\n",
    "                                      output_format='tf', is_train=True)\n",
    "    targets = []\n",
    "    for _, y in val_generator:\n",
    "        targets.extend(y)\n",
    "\n",
    "    return roc_auc_score(targets, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50b0a259",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T15:28:06.374097Z",
     "iopub.status.busy": "2022-08-01T15:28:06.373368Z",
     "iopub.status.idle": "2022-08-01T15:28:06.435986Z",
     "shell.execute_reply": "2022-08-01T15:28:06.435163Z"
    },
    "papermill": {
     "duration": 0.073723,
     "end_time": "2022-08-01T15:28:06.438033",
     "exception": false,
     "start_time": "2022-08-01T15:28:06.364310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inference(model, dataset_test, batch_size=32) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    функция, которая делает предикты на новых данных, возвращает pd.DataFrame из двух колонок:\n",
    "    (app_id, score)\n",
    "    :param model: tf.keras.Model\n",
    "    :param dataset_test: путь до директории с последовательностями\n",
    "    :param batch_size: размер батча\n",
    "    :return: pd.DataFrame из двух колонок: (app_id, score)\n",
    "    \"\"\"\n",
    "    app_ids = []\n",
    "    test_generator = batches_generator(dataset_test, batch_size=batch_size, shuffle=False,\n",
    "                                       is_train=False, output_format='tf')\n",
    "    \n",
    "    preds = model.predict(test_generator).flatten()\n",
    "    \n",
    "    app_ids = []\n",
    "    test_generator = batches_generator(dataset_test, batch_size=batch_size, shuffle=False, \n",
    "                                       is_train=False, output_format='tf')\n",
    "    for _, y in test_generator:\n",
    "        app_ids.extend(y)\n",
    "        \n",
    "    return pd.DataFrame({\n",
    "        'app_id': app_ids,\n",
    "        'score': preds\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6579183a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T15:28:06.456275Z",
     "iopub.status.busy": "2022-08-01T15:28:06.455995Z",
     "iopub.status.idle": "2022-08-01T15:28:06.530087Z",
     "shell.execute_reply": "2022-08-01T15:28:06.529263Z"
    },
    "papermill": {
     "duration": 0.085291,
     "end_time": "2022-08-01T15:28:06.532206",
     "exception": false,
     "start_time": "2022-08-01T15:28:06.446915",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('../input/alfabattle2-sandbox/constants_for_rnn/constants_for_rnn/embedding_projections.pkl', 'rb') as f:\n",
    "    embedding_projections = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f4d0902",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T15:28:06.550096Z",
     "iopub.status.busy": "2022-08-01T15:28:06.549365Z",
     "iopub.status.idle": "2022-08-01T15:28:06.616175Z",
     "shell.execute_reply": "2022-08-01T15:28:06.615339Z"
    },
    "papermill": {
     "duration": 0.078013,
     "end_time": "2022-08-01T15:28:06.618383",
     "exception": false,
     "start_time": "2022-08-01T15:28:06.540370",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transactions_rnn(transactions_cat_features, embedding_projections, product_col_name='product', \n",
    "                          rnn_units=128, classifier_units=32, optimizer=None):\n",
    "    if not optimizer:\n",
    "        optimizer = keras.optimizers.Adam(lr=1e-3)\n",
    "        \n",
    "    inputs = []\n",
    "    cat_embeds = []\n",
    "    \n",
    "    for feature_name in transactions_cat_features:\n",
    "        inp = L.Input(shape=(None, ), dtype='uint32', name=f'input_{feature_name}')\n",
    "        inputs.append(inp)\n",
    "        source_size, projection = embedding_projections[feature_name]\n",
    "        emb = L.Embedding(source_size+1, projection, trainable=True, mask_zero=False, name=f'embedding_{feature_name}')(inp)\n",
    "        cat_embeds.append(emb)\n",
    "    \n",
    "    # product feature\n",
    "    inp = L.Input(shape=(1, ), dtype='uint32', name=f'input_product')\n",
    "    inputs.append(inp)\n",
    "    source_size, projection = embedding_projections['product']\n",
    "    product_emb = L.Embedding(source_size+1, projection, trainable=True, mask_zero=False, name=f'embedding_product')(inp)\n",
    "    product_emb_reshape = L.Reshape((projection, ))(product_emb)\n",
    "    \n",
    "    concated_cat_embeds = L.concatenate(cat_embeds)\n",
    "    \n",
    "    last_state = L.GRU(units=rnn_units)(concated_cat_embeds)\n",
    "    \n",
    "    combined_inp = L.concatenate([last_state, product_emb_reshape])\n",
    "    \n",
    "    dense_intermediate = L.Dense(classifier_units, activation='relu', )(combined_inp)\n",
    "    proba = L.Dense(1, activation='sigmoid')(dense_intermediate)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=proba)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d69171ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T15:28:06.636453Z",
     "iopub.status.busy": "2022-08-01T15:28:06.636162Z",
     "iopub.status.idle": "2022-08-01T15:28:06.704685Z",
     "shell.execute_reply": "2022-08-01T15:28:06.703866Z"
    },
    "papermill": {
     "duration": 0.079739,
     "end_time": "2022-08-01T15:28:06.706672",
     "exception": false,
     "start_time": "2022-08-01T15:28:06.626933",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bigru_pooling_model(transactions_cat_features, embedding_projections, product_col_name='product', \n",
    "                          rnn_units=128, classifier_units=32, optimizer=None):\n",
    "    if not optimizer:\n",
    "        optimizer = keras.optimizers.Adam(lr=1e-3)\n",
    "        \n",
    "    inputs = []\n",
    "    cat_embeds = []\n",
    "    \n",
    "    for feature_name in transactions_cat_features:\n",
    "        inp = L.Input(shape=(None, ), dtype='uint32', name=f'input_{feature_name}')\n",
    "        inputs.append(inp)\n",
    "        source_size, projection = embedding_projections[feature_name]\n",
    "        emb = L.Embedding(source_size+1, projection, trainable=True, mask_zero=False, name=f'embedding_{feature_name}')(inp)\n",
    "        cat_embeds.append(emb)\n",
    "    \n",
    "    # product feature\n",
    "    inp = L.Input(shape=(1, ), dtype='uint32', name=f'input_product')\n",
    "    inputs.append(inp)\n",
    "    source_size, projection = embedding_projections['product']\n",
    "    product_emb = L.Embedding(source_size+1, projection, trainable=True, mask_zero=False, name=f'embedding_product')(inp)\n",
    "    product_emb_reshape = L.Reshape((projection, ))(product_emb)\n",
    "    \n",
    "    concated_cat_embeds = L.concatenate(cat_embeds)\n",
    "    dropout_embeds = L.SpatialDropout1D(0.05)(concated_cat_embeds)\n",
    "    \n",
    "    sequences = L.Bidirectional(L.GRU(units=rnn_units, return_sequences=True))(dropout_embeds)\n",
    "    \n",
    "    pooled_avg_sequences = L.GlobalAveragePooling1D()(sequences)\n",
    "    pooled_max_sequences = L.GlobalMaxPooling1D()(sequences)\n",
    "    \n",
    "    concated = L.concatenate([pooled_avg_sequences, pooled_max_sequences, product_emb_reshape])\n",
    "    \n",
    "    dense_intermediate = L.Dense(classifier_units, activation='relu', \n",
    "                                 kernel_regularizer=keras.regularizers.L1L2(1e-7, 1e-5))(concated)\n",
    "    \n",
    "    proba = L.Dense(1, activation='sigmoid')(dense_intermediate)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=proba)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f77d81c",
   "metadata": {
    "papermill": {
     "duration": 0.008039,
     "end_time": "2022-08-01T15:28:06.722996",
     "exception": false,
     "start_time": "2022-08-01T15:28:06.714957",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21ee1ee1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T15:28:06.740928Z",
     "iopub.status.busy": "2022-08-01T15:28:06.740348Z",
     "iopub.status.idle": "2022-08-01T15:28:09.566927Z",
     "shell.execute_reply": "2022-08-01T15:28:09.565563Z"
    },
    "papermill": {
     "duration": 2.838726,
     "end_time": "2022-08-01T15:28:09.570020",
     "exception": false,
     "start_time": "2022-08-01T15:28:06.731294",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove './rnn_baseline/checkpoints/pytorch_baseline': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "! mkdir ./rnn_baseline\n",
    "\n",
    "! mkdir ./rnn_baseline/checkpoints\n",
    "\n",
    "! rm -r ./rnn_baseline/checkpoints/pytorch_baseline\n",
    "! mkdir ./rnn_baseline/checkpoints/pytorch_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "43689e2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T15:28:09.590935Z",
     "iopub.status.busy": "2022-08-01T15:28:09.590181Z",
     "iopub.status.idle": "2022-08-01T15:28:09.665266Z",
     "shell.execute_reply": "2022-08-01T15:28:09.664326Z"
    },
    "papermill": {
     "duration": 0.087992,
     "end_time": "2022-08-01T15:28:09.667646",
     "exception": false,
     "start_time": "2022-08-01T15:28:09.579654",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_to_checkpoints = './rnn_baseline/checkpoints/pytorch_baseline/'\n",
    "es = EarlyStopping(patience=3, mode='max', verbose=True, save_path=os.path.join(path_to_checkpoints, 'best_checkpoint.pt'), \n",
    "                   metric_name='ROC-AUC', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d9b6701",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T15:28:09.687468Z",
     "iopub.status.busy": "2022-08-01T15:28:09.686749Z",
     "iopub.status.idle": "2022-08-01T15:28:09.749371Z",
     "shell.execute_reply": "2022-08-01T15:28:09.748541Z"
    },
    "papermill": {
     "duration": 0.074622,
     "end_time": "2022-08-01T15:28:09.751518",
     "exception": false,
     "start_time": "2022-08-01T15:28:09.676896",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "train_batch_size = 128\n",
    "val_batch_szie = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "030e63a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T15:28:09.769789Z",
     "iopub.status.busy": "2022-08-01T15:28:09.768983Z",
     "iopub.status.idle": "2022-08-01T15:28:15.638516Z",
     "shell.execute_reply": "2022-08-01T15:28:15.637550Z"
    },
    "papermill": {
     "duration": 5.881306,
     "end_time": "2022-08-01T15:28:15.641117",
     "exception": false,
     "start_time": "2022-08-01T15:28:09.759811",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n",
      "2022-08-01 15:28:09.881023: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-01 15:28:09.882158: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-01 15:28:09.882849: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-01 15:28:09.883654: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-01 15:28:09.883934: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-01 15:28:09.884595: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-01 15:28:09.885252: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-01 15:28:14.705622: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-01 15:28:14.706428: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-01 15:28:14.707132: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-01 15:28:14.707735: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15047 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    }
   ],
   "source": [
    "model = bigru_pooling_model(transaction_features, embedding_projections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e965a59d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T15:28:15.661156Z",
     "iopub.status.busy": "2022-08-01T15:28:15.659584Z",
     "iopub.status.idle": "2022-08-01T15:28:15.730542Z",
     "shell.execute_reply": "2022-08-01T15:28:15.729675Z"
    },
    "papermill": {
     "duration": 0.084333,
     "end_time": "2022-08-01T15:28:15.734405",
     "exception": false,
     "start_time": "2022-08-01T15:28:15.650072",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_currency (InputLayer)     [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_operation_kind (InputLaye [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_card_type (InputLayer)    [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_operation_type (InputLaye [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_operation_type_group (Inp [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_ecommerce_flag (InputLaye [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_payment_system (InputLaye [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_income_flag (InputLayer)  [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_mcc (InputLayer)          [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_country (InputLayer)      [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_city (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_mcc_category (InputLayer) [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_day_of_week (InputLayer)  [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_hour (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_weekofyear (InputLayer)   [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_amnt (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_days_before (InputLayer)  [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_hour_diff (InputLayer)    [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_currency (Embedding)  (None, None, 6)      72          input_currency[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "embedding_operation_kind (Embed (None, None, 5)      40          input_operation_kind[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_card_type (Embedding) (None, None, 29)     5104        input_card_type[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_operation_type (Embed (None, None, 9)      207         input_operation_type[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_operation_type_group  (None, None, 3)      15          input_operation_type_group[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "embedding_ecommerce_flag (Embed (None, None, 3)      12          input_ecommerce_flag[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_payment_system (Embed (None, None, 5)      40          input_payment_system[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_income_flag (Embeddin (None, None, 3)      12          input_income_flag[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "embedding_mcc (Embedding)       (None, None, 22)     2398        input_mcc[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_country (Embedding)   (None, None, 9)      225         input_country[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "embedding_city (Embedding)      (None, None, 28)     4592        input_city[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_mcc_category (Embeddi (None, None, 10)     290         input_mcc_category[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_day_of_week (Embeddin (None, None, 5)      40          input_day_of_week[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "embedding_hour (Embedding)      (None, None, 9)      225         input_hour[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_weekofyear (Embedding (None, None, 15)     810         input_weekofyear[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "embedding_amnt (Embedding)      (None, None, 6)      66          input_amnt[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_days_before (Embeddin (None, None, 9)      216         input_days_before[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "embedding_hour_diff (Embedding) (None, None, 6)      66          input_hour_diff[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, None, 182)    0           embedding_currency[0][0]         \n",
      "                                                                 embedding_operation_kind[0][0]   \n",
      "                                                                 embedding_card_type[0][0]        \n",
      "                                                                 embedding_operation_type[0][0]   \n",
      "                                                                 embedding_operation_type_group[0]\n",
      "                                                                 embedding_ecommerce_flag[0][0]   \n",
      "                                                                 embedding_payment_system[0][0]   \n",
      "                                                                 embedding_income_flag[0][0]      \n",
      "                                                                 embedding_mcc[0][0]              \n",
      "                                                                 embedding_country[0][0]          \n",
      "                                                                 embedding_city[0][0]             \n",
      "                                                                 embedding_mcc_category[0][0]     \n",
      "                                                                 embedding_day_of_week[0][0]      \n",
      "                                                                 embedding_hour[0][0]             \n",
      "                                                                 embedding_weekofyear[0][0]       \n",
      "                                                                 embedding_amnt[0][0]             \n",
      "                                                                 embedding_days_before[0][0]      \n",
      "                                                                 embedding_hour_diff[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d (SpatialDropo (None, None, 182)    0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_product (InputLayer)      [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, None, 256)    239616      spatial_dropout1d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "embedding_product (Embedding)   (None, 1, 4)         24          input_product[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 256)          0           bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d (GlobalMax (None, 256)          0           bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 4)            0           embedding_product[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 516)          0           global_average_pooling1d[0][0]   \n",
      "                                                                 global_max_pooling1d[0][0]       \n",
      "                                                                 reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 32)           16544       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            33          dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 270,647\n",
      "Trainable params: 270,647\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "66385924",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T15:28:15.754221Z",
     "iopub.status.busy": "2022-08-01T15:28:15.753439Z",
     "iopub.status.idle": "2022-08-01T16:57:08.619270Z",
     "shell.execute_reply": "2022-08-01T16:57:08.616439Z"
    },
    "papermill": {
     "duration": 5334.564516,
     "end_time": "2022-08-01T16:57:10.308059",
     "exception": false,
     "start_time": "2022-08-01T15:28:15.743543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-01 15:28:22.387279: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-08-01 15:28:27.795523: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7270/7270 [==============================] - 423s 57ms/step - loss: 0.1091\n",
      "Validation ROC-AUC improved (-inf --> 0.773930).  Saving model ...\n",
      "Epoch 1 completed. Train roc-auc: 0.7767462874538154, Val roc-auc: 0.7739301128974752\n",
      "Starting epoch 2\n",
      "Epoch 2/2\n",
      "7270/7270 [==============================] - 372s 51ms/step - loss: 0.1046\n",
      "Validation ROC-AUC improved (0.773930 --> 0.780469).  Saving model ...\n",
      "Epoch 2 completed. Train roc-auc: 0.7916940914445876, Val roc-auc: 0.7804689415654434\n",
      "Starting epoch 3\n",
      "Epoch 3/3\n",
      "7270/7270 [==============================] - 371s 51ms/step - loss: 0.1027\n",
      "No imporvement in Validation ROC-AUC. Current: 0.774188. Current best: 0.780469\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch 3 completed. Train roc-auc: 0.7962300899735335, Val roc-auc: 0.7741876687484989\n",
      "Starting epoch 4\n",
      "Epoch 4/4\n",
      "7270/7270 [==============================] - 380s 52ms/step - loss: 0.1014\n",
      "Validation ROC-AUC improved (0.780469 --> 0.782836).  Saving model ...\n",
      "Epoch 4 completed. Train roc-auc: 0.8140886666681895, Val roc-auc: 0.782835954955033\n",
      "Starting epoch 5\n",
      "Epoch 5/5\n",
      "7270/7270 [==============================] - 375s 52ms/step - loss: 0.0999\n",
      "No imporvement in Validation ROC-AUC. Current: 0.776717. Current best: 0.782836\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch 5 completed. Train roc-auc: 0.8242748840719616, Val roc-auc: 0.7767171113260524\n",
      "Starting epoch 6\n",
      "Epoch 6/6\n",
      "7270/7270 [==============================] - 376s 52ms/step - loss: 0.0979\n",
      "No imporvement in Validation ROC-AUC. Current: 0.774526. Current best: 0.782836\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Epoch 6 completed. Train roc-auc: 0.8470173939400595, Val roc-auc: 0.7745260618757955\n",
      "Starting epoch 7\n",
      "Epoch 7/7\n",
      "7270/7270 [==============================] - 382s 53ms/step - loss: 0.0954\n",
      "No imporvement in Validation ROC-AUC. Current: 0.768762. Current best: 0.782836\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping reached. Stop training...\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print(f'Starting epoch {epoch+1}')\n",
    "    train_epoch(model, dataset_train, batch_size=train_batch_size, shuffle=True, cur_epoch=epoch, \n",
    "                steps_per_epoch=7270)\n",
    "    \n",
    "    val_roc_auc = eval_model(model, dataset_val, batch_size=val_batch_szie)\n",
    "    model.save_weights(os.path.join(path_to_checkpoints, f'epoch_{epoch+1}_val_{val_roc_auc:.3f}.hdf5'))\n",
    "    \n",
    "    es(val_roc_auc, model)\n",
    "    \n",
    "    if es.early_stop:\n",
    "        print('Early stopping reached. Stop training...')\n",
    "        break\n",
    "        \n",
    "    train_roc_auc = eval_model(model, dataset_train, batch_size=val_batch_szie)\n",
    "    print(f'Epoch {epoch+1} completed. Train roc-auc: {train_roc_auc}, Val roc-auc: {val_roc_auc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5367.739472,
   "end_time": "2022-08-01T16:57:15.622525",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-08-01T15:27:47.883053",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
