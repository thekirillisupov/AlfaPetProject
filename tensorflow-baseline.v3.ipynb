{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14a37cde",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-08-02T05:06:14.952738Z",
     "iopub.status.busy": "2022-08-02T05:06:14.952118Z",
     "iopub.status.idle": "2022-08-02T05:06:22.888305Z",
     "shell.execute_reply": "2022-08-02T05:06:22.886223Z"
    },
    "papermill": {
     "duration": 7.963083,
     "end_time": "2022-08-02T05:06:22.891128",
     "exception": false,
     "start_time": "2022-08-02T05:06:14.928045",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers as L\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af70e640",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T05:06:22.905684Z",
     "iopub.status.busy": "2022-08-02T05:06:22.904446Z",
     "iopub.status.idle": "2022-08-02T05:06:22.960455Z",
     "shell.execute_reply": "2022-08-02T05:06:22.959544Z"
    },
    "papermill": {
     "duration": 0.065071,
     "end_time": "2022-08-02T05:06:22.962564",
     "exception": false,
     "start_time": "2022-08-02T05:06:22.897493",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAIN_TRANSACTIONS_PATH = '../input/alfabattle2-sandbox/alfabattle2_sand_alfabattle2_train_transactions_contest/train_transactions_contest'\n",
    "TEST_TRANSACTIONS_PATH = '../input/alfabattle2-sandbox/alfabattle2_sand_alfabattle2_test_transactions_contest/test_transactions_contest'\n",
    "\n",
    "TRAIN_TARGET_PATH = '../input/alfabattle2-sandbox/alfabattle2_sand_alfabattle2_train_target.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2f1e3e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T05:06:22.975666Z",
     "iopub.status.busy": "2022-08-02T05:06:22.975333Z",
     "iopub.status.idle": "2022-08-02T05:06:23.266692Z",
     "shell.execute_reply": "2022-08-02T05:06:23.265724Z"
    },
    "papermill": {
     "duration": 0.300596,
     "end_time": "2022-08-02T05:06:23.269217",
     "exception": false,
     "start_time": "2022-08-02T05:06:22.968621",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_frame = pd.read_csv(TRAIN_TARGET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0490f9a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T05:06:23.282908Z",
     "iopub.status.busy": "2022-08-02T05:06:23.282590Z",
     "iopub.status.idle": "2022-08-02T05:06:23.342881Z",
     "shell.execute_reply": "2022-08-02T05:06:23.341978Z"
    },
    "papermill": {
     "duration": 0.069633,
     "end_time": "2022-08-02T05:06:23.345252",
     "exception": false,
     "start_time": "2022-08-02T05:06:23.275619",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_parquet_dataset_from_local(path_to_dataset: str, start_from: int = 0,\n",
    "                                     num_parts_to_read: int = 2, columns=None, verbose=False) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    читает num_parts_to_read партиций, преобразует их к pd.DataFrame и возвращает\n",
    "    :param path_to_dataset: путь до директории с партициями\n",
    "    :param start_from: номер партиции, с которой начать чтение\n",
    "    :param num_parts_to_read: количество партиций, которые требуется прочитать\n",
    "    :param columns: список колонок, которые нужно прочитать из партиции\n",
    "    :return: pd.DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    res = []\n",
    "    dataset_paths = sorted([os.path.join(path_to_dataset, filename) for filename in os.listdir(path_to_dataset) \n",
    "                              if filename.startswith('part')])\n",
    "    \n",
    "    start_from = max(0, start_from)\n",
    "    chunks = dataset_paths[start_from: start_from + num_parts_to_read]\n",
    "    if verbose:\n",
    "        print('Reading chunks:\\n')\n",
    "        for chunk in chunks:\n",
    "            print(chunk)\n",
    "    for chunk_path in tqdm_notebook(chunks, desc=\"Reading dataset with pandas\"):\n",
    "        chunk = pd.read_parquet(chunk_path,columns=columns)\n",
    "        res.append(chunk)\n",
    "    return pd.concat(res).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2966b95a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T05:06:23.358857Z",
     "iopub.status.busy": "2022-08-02T05:06:23.358545Z",
     "iopub.status.idle": "2022-08-02T05:06:23.419380Z",
     "shell.execute_reply": "2022-08-02T05:06:23.418480Z"
    },
    "papermill": {
     "duration": 0.070033,
     "end_time": "2022-08-02T05:06:23.421454",
     "exception": false,
     "start_time": "2022-08-02T05:06:23.351421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "features = ['currency', 'operation_kind', 'card_type', 'operation_type', 'operation_type_group', 'ecommerce_flag',\n",
    "            'payment_system', 'income_flag', 'mcc', 'country', 'city', 'mcc_category', 'day_of_week',\n",
    "            'hour', 'weekofyear', 'amnt', 'days_before', 'hour_diff']\n",
    "\n",
    "def pad_sequence(array, max_len) -> np.array:\n",
    "    \"\"\"\n",
    "    принимает список списков (array) и делает padding каждого вложенного списка до max_len\n",
    "    :param array: список списков\n",
    "    :param max_len: максимальная длина до которой нужно сделать padding\n",
    "    :return: np.array после padding каждого вложенного списка до одинаковой длины\n",
    "    \"\"\"\n",
    "    add_zeros = max_len - len(array[0])\n",
    "    return np.array([list(x) + [0] * add_zeros for x in array])\n",
    "\n",
    "\n",
    "def truncate(x, num_last_transactions=750):\n",
    "    return x.values.transpose()[:, -num_last_transactions:].tolist()\n",
    "\n",
    "\n",
    "def transform_transactions_to_sequences(transactions_frame: pd.DataFrame,\n",
    "                                        num_last_transactions=750) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    принимает frame с транзакциями клиентов, сортирует транзакции по клиентам\n",
    "    (внутри клиента сортирует транзакции по возрастанию), берет num_last_transactions танзакций,\n",
    "    возвращает новый pd.DataFrame с двумя колонками: app_id и sequences.\n",
    "    каждое значение в колонке sequences - это список списков.\n",
    "    каждый список - значение одного конкретного признака во всех клиентских транзакциях.\n",
    "    Всего признаков len(features), поэтому будет len(features) списков.\n",
    "    Данная функция крайне полезна для подготовки датасета для работы с нейронными сетями.\n",
    "    :param transactions_frame: фрейм с транзакциями клиентов\n",
    "    :param num_last_transactions: количество транзакций клиента, которые будут рассмотрены\n",
    "    :return: pd.DataFrame из двух колонок (app_id, sequences)\n",
    "    \"\"\"\n",
    "    return transactions_frame \\\n",
    "        .sort_values(['app_id', 'transaction_number']) \\\n",
    "        .groupby(['app_id'])[features] \\\n",
    "        .apply(lambda x: truncate(x, num_last_transactions=num_last_transactions)) \\\n",
    "        .reset_index().rename(columns={0: 'sequences'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "586891e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T05:06:23.434885Z",
     "iopub.status.busy": "2022-08-02T05:06:23.434609Z",
     "iopub.status.idle": "2022-08-02T05:06:23.495679Z",
     "shell.execute_reply": "2022-08-02T05:06:23.494808Z"
    },
    "papermill": {
     "duration": 0.070379,
     "end_time": "2022-08-02T05:06:23.497874",
     "exception": false,
     "start_time": "2022-08-02T05:06:23.427495",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_padded_buckets(frame_of_sequences: pd.DataFrame, bucket_info: Dict[int, int],\n",
    "                          save_to_file_path=None, has_target=True):\n",
    "    \"\"\"\n",
    "    Функция реализует sequence_bucketing технику для обучения нейронных сетей.\n",
    "    Принимает на вход frame_of_sequences (результат работы функции transform_transactions_to_sequences),\n",
    "    словарь bucket_info, где для последовательности каждой длины указано, до какой максимальной длины нужно делать\n",
    "    padding, далее группирует транзакции по бакетам (на основе длины), делает padding транзакций и сохраняет результат\n",
    "    в pickle файл, если нужно\n",
    "    :param frame_of_sequences: pd.DataFrame c транзакциями (результат применения transform_transactions_to_sequences)\n",
    "    :param bucket_info: словарь, где для последовательности каждой длины указано, до какой максимальной длины нужно делать\n",
    "    padding\n",
    "    :param save_to_file_path: опциональный путь до файла, куда нужно сохранить результат\n",
    "    :param has_target: флаг, есть ли в frame_of_sequences целевая переменная или нет. Если есть, то\n",
    "    будет записано в результат\n",
    "    :return: возвращает словарь с следюущими ключами (padded_sequences, targets, app_id, products)\n",
    "    \"\"\"\n",
    "    frame_of_sequences['bucket_idx'] = frame_of_sequences.sequence_length.map(bucket_info)\n",
    "    padded_seq = []\n",
    "    targets = []\n",
    "    app_ids = []\n",
    "    products = []\n",
    "\n",
    "    for size, bucket in frame_of_sequences.groupby('bucket_idx'):\n",
    "        padded_sequences = bucket.sequences.apply(lambda x: pad_sequence(x, size)).values\n",
    "        padded_sequences = np.array([np.array(x) for x in padded_sequences])\n",
    "        padded_seq.append(padded_sequences)\n",
    "\n",
    "        if has_target:\n",
    "            targets.append(bucket.flag.values)\n",
    "\n",
    "        app_ids.append(bucket.app_id.values)\n",
    "        products.append(bucket['product'].values)\n",
    "\n",
    "    frame_of_sequences.drop(columns=['bucket_idx'], inplace=True)\n",
    "\n",
    "    dict_result = {\n",
    "        'padded_sequences': np.array(padded_seq, dtype=object),\n",
    "        'targets': np.array(targets, dtype=object) if targets else [],\n",
    "        'app_id': np.array(app_ids, dtype=object),\n",
    "        'products': np.array(products, dtype=object),\n",
    "    }\n",
    "\n",
    "    if save_to_file_path:\n",
    "        with open(save_to_file_path, 'wb') as f:\n",
    "            pickle.dump(dict_result, f)\n",
    "    return dict_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bd9acd4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T05:06:23.512835Z",
     "iopub.status.busy": "2022-08-02T05:06:23.511358Z",
     "iopub.status.idle": "2022-08-02T05:06:23.592153Z",
     "shell.execute_reply": "2022-08-02T05:06:23.591220Z"
    },
    "papermill": {
     "duration": 0.090491,
     "end_time": "2022-08-02T05:06:23.594474",
     "exception": false,
     "start_time": "2022-08-02T05:06:23.503983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../input/alfabattle2-sandbox/constants_for_rnn/constants_for_rnn/buckets_info.pkl', 'rb') as f:\n",
    "    mapping_seq_len_to_padded_len = pickle.load(f)\n",
    "    \n",
    "with open('../input/alfabattle2-sandbox/constants_for_rnn/constants_for_rnn/dense_features_buckets.pkl', 'rb') as f:\n",
    "    dense_features_buckets = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ec9a9d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T05:06:23.608747Z",
     "iopub.status.busy": "2022-08-02T05:06:23.607859Z",
     "iopub.status.idle": "2022-08-02T05:06:23.669717Z",
     "shell.execute_reply": "2022-08-02T05:06:23.668806Z"
    },
    "papermill": {
     "duration": 0.071523,
     "end_time": "2022-08-02T05:06:23.672168",
     "exception": false,
     "start_time": "2022-08-02T05:06:23.600645",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_buckets_from_transactions(path_to_dataset, save_to_path, frame_with_ids = None, \n",
    "                                     num_parts_to_preprocess_at_once: int = 1, \n",
    "                                     num_parts_total=50, has_target=False):\n",
    "    block = 0\n",
    "    for step in tqdm(range(0, num_parts_total, num_parts_to_preprocess_at_once), \n",
    "                                   desc=\"Transforming transactions data\"):\n",
    "        transactions_frame = read_parquet_dataset_from_local(path_to_dataset, step, num_parts_to_preprocess_at_once, \n",
    "                                                             verbose=True)\n",
    "        for dense_col in ['amnt', 'days_before', 'hour_diff']:\n",
    "            transactions_frame[dense_col] = np.digitize(transactions_frame[dense_col], bins=dense_features_buckets[dense_col])\n",
    "            \n",
    "        seq = transform_transactions_to_sequences(transactions_frame)\n",
    "        seq['sequence_length'] = seq.sequences.apply(lambda x: len(x[1]))\n",
    "        \n",
    "        if frame_with_ids is not None:\n",
    "            seq = seq.merge(frame_with_ids, on='app_id')\n",
    "\n",
    "        block_as_str = str(block)\n",
    "        if len(block_as_str) == 1:\n",
    "            block_as_str = '00' + block_as_str\n",
    "        else:\n",
    "            block_as_str = '0' + block_as_str\n",
    "            how\n",
    "        processed_fragment =  create_padded_buckets(seq, mapping_seq_len_to_padded_len, has_target=has_target, \n",
    "                                                    save_to_file_path=os.path.join(save_to_path, \n",
    "                                                                                   f'processed_chunk_{block_as_str}.pkl'))\n",
    "        block += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af5d93ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T05:06:23.686189Z",
     "iopub.status.busy": "2022-08-02T05:06:23.685807Z",
     "iopub.status.idle": "2022-08-02T05:06:23.767012Z",
     "shell.execute_reply": "2022-08-02T05:06:23.766087Z"
    },
    "papermill": {
     "duration": 0.090727,
     "end_time": "2022-08-02T05:06:23.769288",
     "exception": false,
     "start_time": "2022-08-02T05:06:23.678561",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../input/train-val-buckets/val_buckets/processed_chunk_000.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_001.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_002.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_003.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_004.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_005.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_006.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_007.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_008.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_009.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_010.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_011.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_012.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_013.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_014.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_015.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_016.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_017.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_018.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_019.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_020.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_021.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_022.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_023.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_024.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_025.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_026.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_027.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_028.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_029.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_030.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_031.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_032.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_033.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_034.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_035.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_036.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_037.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_038.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_039.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_040.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_041.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_042.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_043.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_044.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_045.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_046.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_047.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_048.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_049.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_dataset = '../input/train-val-buckets/val_buckets'\n",
    "dir_with_datasets = os.listdir(path_to_dataset)\n",
    "dataset_val = sorted([os.path.join(path_to_dataset, x) for x in dir_with_datasets])\n",
    "dataset_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55a98133",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T05:06:23.783973Z",
     "iopub.status.busy": "2022-08-02T05:06:23.782529Z",
     "iopub.status.idle": "2022-08-02T05:06:23.849815Z",
     "shell.execute_reply": "2022-08-02T05:06:23.848900Z"
    },
    "papermill": {
     "duration": 0.076483,
     "end_time": "2022-08-02T05:06:23.851970",
     "exception": false,
     "start_time": "2022-08-02T05:06:23.775487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../input/train-val-buckets/train_buckets/processed_chunk_000.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_001.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_002.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_003.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_004.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_005.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_006.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_007.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_008.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_009.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_010.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_011.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_012.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_013.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_014.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_015.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_016.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_017.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_018.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_019.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_020.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_021.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_022.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_023.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_024.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_025.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_026.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_dataset = '../input/train-val-buckets/train_buckets'\n",
    "dir_with_datasets = os.listdir(path_to_dataset)\n",
    "dataset_train = sorted([os.path.join(path_to_dataset, x) for x in dir_with_datasets])\n",
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8557e694",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T05:06:23.866509Z",
     "iopub.status.busy": "2022-08-02T05:06:23.866214Z",
     "iopub.status.idle": "2022-08-02T05:06:23.987595Z",
     "shell.execute_reply": "2022-08-02T05:06:23.986205Z"
    },
    "papermill": {
     "duration": 0.131449,
     "end_time": "2022-08-02T05:06:23.989791",
     "exception": false,
     "start_time": "2022-08-02T05:06:23.858342",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "059e12c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T05:06:24.004951Z",
     "iopub.status.busy": "2022-08-02T05:06:24.004647Z",
     "iopub.status.idle": "2022-08-02T05:06:24.073535Z",
     "shell.execute_reply": "2022-08-02T05:06:24.072593Z"
    },
    "papermill": {
     "duration": 0.079022,
     "end_time": "2022-08-02T05:06:24.075958",
     "exception": false,
     "start_time": "2022-08-02T05:06:23.996936",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "transaction_features = ['currency', 'operation_kind', 'card_type', 'operation_type',\n",
    "                        'operation_type_group', 'ecommerce_flag', 'payment_system',\n",
    "                        'income_flag', 'mcc', 'country', 'city', 'mcc_category',\n",
    "                        'day_of_week', 'hour', 'weekofyear', 'amnt', 'days_before', 'hour_diff']\n",
    "\n",
    "def batches_generator(list_of_paths, batch_size=32, shuffle=False, is_infinite=False,\n",
    "                      verbose=False, device=None, output_format='tf', is_train=True):\n",
    "    \"\"\"\n",
    "    функция для создания батчей на вход для нейронной сети для моделей на keras и pytorch.\n",
    "    так же может использоваться как функция на стадии инференса\n",
    "    :param list_of_paths: путь до директории с предобработанными последовательностями\n",
    "    :param batch_size: размер батча\n",
    "    :param shuffle: флаг, если True, то перемешивает list_of_paths и так же\n",
    "    перемешивает последовательности внутри файла\n",
    "    :param is_infinite: флаг, если True,  то создает бесконечный генератор батчей\n",
    "    :param verbose: флаг, если True, то печатает текущий обрабатываемый файл\n",
    "    :param device: device на который положить данные, если работа на торче\n",
    "    :param output_format: допустимые варианты ['tf', 'torch']. Если 'torch', то возвращает словарь,\n",
    "    где ключи - батчи из признаков, таргетов и app_id. Если 'tf', то возвращает картеж: лист input-ов\n",
    "    для модели, и список таргетов.\n",
    "    :param is_train: флаг, Если True, то для кераса вернет (X, y), где X - input-ы в модель, а y - таргеты, \n",
    "    если False, то в y будут app_id; для torch вернет словарь с ключами на device.\n",
    "    :return: бачт из последовательностей и таргетов (или app_id)\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        if shuffle:\n",
    "            np.random.shuffle(list_of_paths)\n",
    "\n",
    "        for path in list_of_paths:\n",
    "            if verbose:\n",
    "                print(f'reading {path}')\n",
    "\n",
    "            with open(path, 'rb') as f:\n",
    "                '''\n",
    "                26.pkl is truncated \n",
    "                '''\n",
    "                if path == '../input/train-val-buckets/train_buckets/processed_chunk_026.pkl':\n",
    "                    continue\n",
    "                data = pickle.load(f)\n",
    "            padded_sequences, targets, products = data['padded_sequences'], data['targets'], data[\n",
    "                'products']\n",
    "            app_ids = data['app_id']\n",
    "            indices = np.arange(len(products))\n",
    "\n",
    "            if shuffle:\n",
    "                np.random.shuffle(indices)\n",
    "                padded_sequences = padded_sequences[indices]\n",
    "                targets = targets[indices]\n",
    "                products = products[indices]\n",
    "                app_ids = app_ids[indices]\n",
    "\n",
    "            for idx in range(len(products)):\n",
    "                bucket, product = padded_sequences[idx], products[idx]\n",
    "                app_id = app_ids[idx]\n",
    "                \n",
    "                if is_train:\n",
    "                    target = targets[idx]\n",
    "                \n",
    "                for jdx in range(0, len(bucket), batch_size):\n",
    "                    batch_sequences = bucket[jdx: jdx + batch_size]\n",
    "                    if is_train:\n",
    "                        batch_targets = target[jdx: jdx + batch_size]\n",
    "                    \n",
    "                    batch_products = product[jdx: jdx + batch_size]\n",
    "                    batch_app_ids = app_id[jdx: jdx + batch_size]\n",
    "                    \n",
    "                    if output_format == 'tf':\n",
    "                        batch_sequences = [batch_sequences[:, i] for i in\n",
    "                                           range(len(transaction_features))]\n",
    "                        \n",
    "                        # append product as input to tf model\n",
    "                        batch_sequences.append(batch_products)\n",
    "                        if is_train:\n",
    "                            yield batch_sequences, batch_targets\n",
    "                        else:\n",
    "                             yield batch_sequences, batch_app_ids\n",
    "                    else:\n",
    "                        batch_sequences = [torch.LongTensor(batch_sequences[:, i]).to(device)\n",
    "                                           for i in range(len(transaction_features))]\n",
    "                        if is_train:\n",
    "                            yield dict(transactions_features=batch_sequences,\n",
    "                                       product=torch.LongTensor(batch_products).to(device),\n",
    "                                       label=torch.LongTensor(batch_targets).to(device),\n",
    "                                       app_id=batch_app_ids)\n",
    "                        else:\n",
    "                            yield dict(transactions_features=batch_sequences,\n",
    "                                       product=torch.LongTensor(batch_products).to(device),\n",
    "                                       app_id=batch_app_ids)\n",
    "        if not is_infinite:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03751335",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T05:06:24.089757Z",
     "iopub.status.busy": "2022-08-02T05:06:24.089463Z",
     "iopub.status.idle": "2022-08-02T05:06:24.152258Z",
     "shell.execute_reply": "2022-08-02T05:06:24.151328Z"
    },
    "papermill": {
     "duration": 0.072081,
     "end_time": "2022-08-02T05:06:24.154440",
     "exception": false,
     "start_time": "2022-08-02T05:06:24.082359",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation metric doesn't improve after a given patience.\"\"\"\n",
    "\n",
    "    def __init__(self, patience=7, mode='min', verbose=False, delta=0, save_path='checkpoint.hdf5', metric_name=None, save_format='tf'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            mode (str): One of ['min', 'max'], whether to maximize or minimaze the metric.\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            save_path (str): Path to saved model\n",
    "        \"\"\"\n",
    "        if mode not in ['min', 'max']:\n",
    "            raise ValueError(f'Unrecognized mode: {mode}!')\n",
    "\n",
    "        self.patience = patience\n",
    "        self.mode = mode\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.best_prev_score = np.Inf if mode == 'min' else -np.Inf\n",
    "        self.delta = delta\n",
    "        self.save_path = save_path\n",
    "        self.metric_name = 'metric' if not metric_name else metric_name\n",
    "        if save_format not in ['torch', 'tf']:\n",
    "            raise ValueError('Expected to save in one of the following formats: [\"torch\", \"tf\"]')\n",
    "        self.save_format = save_format\n",
    "        \n",
    "    def __call__(self, metric_value, model):\n",
    "\n",
    "        score = -metric_value if self.mode == 'min' else metric_value\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(metric_value, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(\n",
    "                f'No imporvement in Validation {self.metric_name}. Current: {score:.6f}. Current best: {self.best_score:.6f}')\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(metric_value, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, metric_value, model):\n",
    "        \"\"\"Saves model when validation loss decrease.\"\"\"\n",
    "        if self.verbose:\n",
    "            print(\n",
    "                f'Validation {self.metric_name} improved ({self.best_prev_score:.6f} --> {metric_value:.6f}).  Saving model ...')\n",
    "        if self.save_format == 'tf':\n",
    "            model.save_weights(self.save_path)\n",
    "        else:\n",
    "            torch.save(model.state_dict(), self.save_path)\n",
    "            \n",
    "        self.best_prev_score = metric_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2859d3",
   "metadata": {
    "papermill": {
     "duration": 0.006149,
     "end_time": "2022-08-02T05:06:24.167089",
     "exception": false,
     "start_time": "2022-08-02T05:06:24.160940",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## TF-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a663c38b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T05:06:24.180459Z",
     "iopub.status.busy": "2022-08-02T05:06:24.180160Z",
     "iopub.status.idle": "2022-08-02T05:06:24.236550Z",
     "shell.execute_reply": "2022-08-02T05:06:24.235656Z"
    },
    "papermill": {
     "duration": 0.06562,
     "end_time": "2022-08-02T05:06:24.238719",
     "exception": false,
     "start_time": "2022-08-02T05:06:24.173099",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, dataset_train, batch_size=64, shuffle=True, cur_epoch=0,\n",
    "                steps_per_epoch=5000, callbacks=None):\n",
    "    \"\"\"\n",
    "    функция обучения модели одну эпоху\n",
    "    :param model: tf.keras.Model\n",
    "    :param dataset_train: путь до директории с последовательностями\n",
    "    :param batch_size: размер батча\n",
    "    :param shuffle: флаг, если True, то перемешивает данные\n",
    "    :param cur_epoch:\n",
    "    :param steps_per_epoch:\n",
    "    :param callbacks: cписок из tf.keras.callbacks или None\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    train_generator = batches_generator(dataset_train, batch_size=batch_size, shuffle=shuffle,\n",
    "                                        output_format='tf', is_train=True)\n",
    "    model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=cur_epoch + 1,\n",
    "              initial_epoch=cur_epoch, callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c861891c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T05:06:24.252478Z",
     "iopub.status.busy": "2022-08-02T05:06:24.252189Z",
     "iopub.status.idle": "2022-08-02T05:06:24.310407Z",
     "shell.execute_reply": "2022-08-02T05:06:24.309531Z"
    },
    "papermill": {
     "duration": 0.067583,
     "end_time": "2022-08-02T05:06:24.312659",
     "exception": false,
     "start_time": "2022-08-02T05:06:24.245076",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval_model(model, dataset_val, batch_size=32) -> float:\n",
    "    \"\"\"\n",
    "    функция для оценки качества модели на отложенной выборке, возвращает roc-auc на валидационной\n",
    "    выборке\n",
    "    :param model: tf.keras.Model\n",
    "    :param dataset_val: путь до директории с последовательностями\n",
    "    :param batch_size: размер батча\n",
    "    :return: val roc-auc score\n",
    "    \"\"\"\n",
    "    val_generator = batches_generator(dataset_val, batch_size=batch_size, shuffle=False,\n",
    "                                      output_format='tf', is_train=True)\n",
    "    preds = model.predict(val_generator).flatten()\n",
    "    val_generator = batches_generator(dataset_val, batch_size=batch_size, shuffle=False,\n",
    "                                      output_format='tf', is_train=True)\n",
    "    targets = []\n",
    "    for _, y in val_generator:\n",
    "        targets.extend(y)\n",
    "\n",
    "    return roc_auc_score(targets, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9fde3037",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T05:06:24.326559Z",
     "iopub.status.busy": "2022-08-02T05:06:24.325803Z",
     "iopub.status.idle": "2022-08-02T05:06:24.383280Z",
     "shell.execute_reply": "2022-08-02T05:06:24.382396Z"
    },
    "papermill": {
     "duration": 0.06683,
     "end_time": "2022-08-02T05:06:24.385679",
     "exception": false,
     "start_time": "2022-08-02T05:06:24.318849",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inference(model, dataset_test, batch_size=32) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    функция, которая делает предикты на новых данных, возвращает pd.DataFrame из двух колонок:\n",
    "    (app_id, score)\n",
    "    :param model: tf.keras.Model\n",
    "    :param dataset_test: путь до директории с последовательностями\n",
    "    :param batch_size: размер батча\n",
    "    :return: pd.DataFrame из двух колонок: (app_id, score)\n",
    "    \"\"\"\n",
    "    app_ids = []\n",
    "    test_generator = batches_generator(dataset_test, batch_size=batch_size, shuffle=False,\n",
    "                                       is_train=False, output_format='tf')\n",
    "    \n",
    "    preds = model.predict(test_generator).flatten()\n",
    "    \n",
    "    app_ids = []\n",
    "    test_generator = batches_generator(dataset_test, batch_size=batch_size, shuffle=False, \n",
    "                                       is_train=False, output_format='tf')\n",
    "    for _, y in test_generator:\n",
    "        app_ids.extend(y)\n",
    "        \n",
    "    return pd.DataFrame({\n",
    "        'app_id': app_ids,\n",
    "        'score': preds\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a3640b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T05:06:24.400719Z",
     "iopub.status.busy": "2022-08-02T05:06:24.399166Z",
     "iopub.status.idle": "2022-08-02T05:06:24.465947Z",
     "shell.execute_reply": "2022-08-02T05:06:24.465016Z"
    },
    "papermill": {
     "duration": 0.076155,
     "end_time": "2022-08-02T05:06:24.468241",
     "exception": false,
     "start_time": "2022-08-02T05:06:24.392086",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('../input/alfabattle2-sandbox/constants_for_rnn/constants_for_rnn/embedding_projections.pkl', 'rb') as f:\n",
    "    embedding_projections = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2cf1e865",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T05:06:24.481958Z",
     "iopub.status.busy": "2022-08-02T05:06:24.481663Z",
     "iopub.status.idle": "2022-08-02T05:06:24.543511Z",
     "shell.execute_reply": "2022-08-02T05:06:24.542598Z"
    },
    "papermill": {
     "duration": 0.071495,
     "end_time": "2022-08-02T05:06:24.545942",
     "exception": false,
     "start_time": "2022-08-02T05:06:24.474447",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transactions_rnn(transactions_cat_features, embedding_projections, product_col_name='product', \n",
    "                          rnn_units=128, classifier_units=32, optimizer=None):\n",
    "    if not optimizer:\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "        \n",
    "    inputs = []\n",
    "    cat_embeds = []\n",
    "    \n",
    "    for feature_name in transactions_cat_features:\n",
    "        inp = L.Input(shape=(None, ), dtype='uint32', name=f'input_{feature_name}')\n",
    "        inputs.append(inp)\n",
    "        source_size, projection = embedding_projections[feature_name]\n",
    "        emb = L.Embedding(source_size+1, projection, trainable=True, mask_zero=False, name=f'embedding_{feature_name}')(inp)\n",
    "        cat_embeds.append(emb)\n",
    "    \n",
    "    # product feature\n",
    "    inp = L.Input(shape=(1, ), dtype='uint32', name=f'input_product')\n",
    "    inputs.append(inp)\n",
    "    source_size, projection = embedding_projections['product']\n",
    "    product_emb = L.Embedding(source_size+1, projection, trainable=True, mask_zero=False, name=f'embedding_product')(inp)\n",
    "    product_emb_reshape = L.Reshape((projection, ))(product_emb)\n",
    "    \n",
    "    concated_cat_embeds = L.concatenate(cat_embeds)\n",
    "    \n",
    "    last_state = L.GRU(units=rnn_units)(concated_cat_embeds)\n",
    "    \n",
    "    combined_inp = L.concatenate([last_state, product_emb_reshape])\n",
    "    \n",
    "    dense_intermediate = L.Dense(classifier_units, activation='relu', )(combined_inp)\n",
    "    proba = L.Dense(1, activation='sigmoid')(dense_intermediate)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=proba)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb90cec4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T05:06:24.560391Z",
     "iopub.status.busy": "2022-08-02T05:06:24.560095Z",
     "iopub.status.idle": "2022-08-02T05:06:24.625427Z",
     "shell.execute_reply": "2022-08-02T05:06:24.624167Z"
    },
    "papermill": {
     "duration": 0.075425,
     "end_time": "2022-08-02T05:06:24.627902",
     "exception": false,
     "start_time": "2022-08-02T05:06:24.552477",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bigru_pooling_model(transactions_cat_features, embedding_projections, product_col_name='product', \n",
    "                          rnn_units=128, classifier_units=32, optimizer=None):\n",
    "    if not optimizer:\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "        \n",
    "    inputs = []\n",
    "    cat_embeds = []\n",
    "    \n",
    "    for feature_name in transactions_cat_features:\n",
    "        inp = L.Input(shape=(None, ), dtype='uint32', name=f'input_{feature_name}')\n",
    "        inputs.append(inp)\n",
    "        source_size, projection = embedding_projections[feature_name]\n",
    "        emb = L.Embedding(source_size+1, projection, trainable=True, mask_zero=False, name=f'embedding_{feature_name}')(inp)\n",
    "        emb_dropout = L.Dropout(.05)(emb)\n",
    "        cat_embeds.append(emb_dropout)\n",
    "    \n",
    "    # product feature\n",
    "    inp = L.Input(shape=(1, ), dtype='uint32', name=f'input_product')\n",
    "    inputs.append(inp)\n",
    "    source_size, projection = embedding_projections['product']\n",
    "    product_emb = L.Embedding(source_size+1, projection, trainable=True, mask_zero=False, name=f'embedding_product')(inp)\n",
    "    product_emb_reshape = L.Reshape((projection, ))(product_emb)\n",
    "    \n",
    "    concated_cat_embeds = L.concatenate(cat_embeds)\n",
    "    dropout_embeds = L.Dropout(.05)(concated_cat_embeds)\n",
    "    \n",
    "    sequences = L.Bidirectional(L.GRU(units=rnn_units, return_sequences=True))(dropout_embeds)\n",
    "    dropout_sequences = L.Dropout(.05)(sequences)\n",
    "    \n",
    "    pooled_avg_sequences = L.GlobalAveragePooling1D()(sequences)\n",
    "    pooled_max_sequences = L.GlobalMaxPooling1D()(sequences)\n",
    "    \n",
    "    concated = L.concatenate([pooled_avg_sequences, pooled_max_sequences, product_emb_reshape])\n",
    "    \n",
    "    dense_intermediate = L.Dense(classifier_units, activation='relu', \n",
    "                                 kernel_regularizer=keras.regularizers.L1L2(1e-7, 1e-5))(concated)\n",
    "    \n",
    "    proba = L.Dense(1, activation='sigmoid')(dense_intermediate)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=proba)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ef97dc",
   "metadata": {
    "papermill": {
     "duration": 0.00601,
     "end_time": "2022-08-02T05:06:24.649431",
     "exception": false,
     "start_time": "2022-08-02T05:06:24.643421",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb3082b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T05:06:24.663256Z",
     "iopub.status.busy": "2022-08-02T05:06:24.662904Z",
     "iopub.status.idle": "2022-08-02T05:06:28.784356Z",
     "shell.execute_reply": "2022-08-02T05:06:28.783089Z"
    },
    "papermill": {
     "duration": 4.131514,
     "end_time": "2022-08-02T05:06:28.787115",
     "exception": false,
     "start_time": "2022-08-02T05:06:24.655601",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove './rnn_baseline/checkpoints/pytorch_baseline': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "! mkdir ./rnn_baseline\n",
    "\n",
    "! mkdir ./rnn_baseline/checkpoints\n",
    "\n",
    "! rm -r ./rnn_baseline/checkpoints/pytorch_baseline\n",
    "! mkdir ./rnn_baseline/checkpoints/pytorch_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d5eb57c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T05:06:28.801765Z",
     "iopub.status.busy": "2022-08-02T05:06:28.801079Z",
     "iopub.status.idle": "2022-08-02T05:06:28.867893Z",
     "shell.execute_reply": "2022-08-02T05:06:28.866943Z"
    },
    "papermill": {
     "duration": 0.076781,
     "end_time": "2022-08-02T05:06:28.870370",
     "exception": false,
     "start_time": "2022-08-02T05:06:28.793589",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_to_checkpoints = './rnn_baseline/checkpoints/pytorch_baseline/'\n",
    "es = EarlyStopping(patience=3, mode='max', verbose=True, save_path=os.path.join(path_to_checkpoints, 'best_checkpoint.pt'), \n",
    "                   metric_name='ROC-AUC', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b9a9225",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T05:06:28.885325Z",
     "iopub.status.busy": "2022-08-02T05:06:28.884200Z",
     "iopub.status.idle": "2022-08-02T05:06:28.940302Z",
     "shell.execute_reply": "2022-08-02T05:06:28.939359Z"
    },
    "papermill": {
     "duration": 0.065345,
     "end_time": "2022-08-02T05:06:28.942590",
     "exception": false,
     "start_time": "2022-08-02T05:06:28.877245",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "train_batch_size = 128\n",
    "val_batch_szie = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e40cace0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T05:06:28.956724Z",
     "iopub.status.busy": "2022-08-02T05:06:28.956207Z",
     "iopub.status.idle": "2022-08-02T05:06:34.826852Z",
     "shell.execute_reply": "2022-08-02T05:06:34.825759Z"
    },
    "papermill": {
     "duration": 5.880446,
     "end_time": "2022-08-02T05:06:34.829606",
     "exception": false,
     "start_time": "2022-08-02T05:06:28.949160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-02 05:06:29.047535: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-02 05:06:29.048694: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-02 05:06:29.049415: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-02 05:06:29.050289: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-02 05:06:29.050649: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-02 05:06:29.051480: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-02 05:06:29.052192: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-02 05:06:33.819289: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-02 05:06:33.820177: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-02 05:06:33.820866: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-02 05:06:33.821491: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15047 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    }
   ],
   "source": [
    "model = bigru_pooling_model(transaction_features, embedding_projections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "096d410c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T05:06:34.844208Z",
     "iopub.status.busy": "2022-08-02T05:06:34.843871Z",
     "iopub.status.idle": "2022-08-02T05:06:34.908237Z",
     "shell.execute_reply": "2022-08-02T05:06:34.907112Z"
    },
    "papermill": {
     "duration": 0.075026,
     "end_time": "2022-08-02T05:06:34.911640",
     "exception": false,
     "start_time": "2022-08-02T05:06:34.836614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_currency (InputLayer)     [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_operation_kind (InputLaye [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_card_type (InputLayer)    [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_operation_type (InputLaye [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_operation_type_group (Inp [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_ecommerce_flag (InputLaye [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_payment_system (InputLaye [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_income_flag (InputLayer)  [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_mcc (InputLayer)          [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_country (InputLayer)      [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_city (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_mcc_category (InputLayer) [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_day_of_week (InputLayer)  [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_hour (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_weekofyear (InputLayer)   [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_amnt (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_days_before (InputLayer)  [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_hour_diff (InputLayer)    [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_currency (Embedding)  (None, None, 6)      72          input_currency[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "embedding_operation_kind (Embed (None, None, 5)      40          input_operation_kind[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_card_type (Embedding) (None, None, 29)     5104        input_card_type[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_operation_type (Embed (None, None, 9)      207         input_operation_type[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_operation_type_group  (None, None, 3)      15          input_operation_type_group[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "embedding_ecommerce_flag (Embed (None, None, 3)      12          input_ecommerce_flag[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_payment_system (Embed (None, None, 5)      40          input_payment_system[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_income_flag (Embeddin (None, None, 3)      12          input_income_flag[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "embedding_mcc (Embedding)       (None, None, 22)     2398        input_mcc[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_country (Embedding)   (None, None, 9)      225         input_country[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "embedding_city (Embedding)      (None, None, 28)     4592        input_city[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_mcc_category (Embeddi (None, None, 10)     290         input_mcc_category[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_day_of_week (Embeddin (None, None, 5)      40          input_day_of_week[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "embedding_hour (Embedding)      (None, None, 9)      225         input_hour[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_weekofyear (Embedding (None, None, 15)     810         input_weekofyear[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "embedding_amnt (Embedding)      (None, None, 6)      66          input_amnt[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_days_before (Embeddin (None, None, 9)      216         input_days_before[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "embedding_hour_diff (Embedding) (None, None, 6)      66          input_hour_diff[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, None, 6)      0           embedding_currency[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, None, 5)      0           embedding_operation_kind[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, None, 29)     0           embedding_card_type[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, None, 9)      0           embedding_operation_type[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, None, 3)      0           embedding_operation_type_group[0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, None, 3)      0           embedding_ecommerce_flag[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, None, 5)      0           embedding_payment_system[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, None, 3)      0           embedding_income_flag[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, None, 22)     0           embedding_mcc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, None, 9)      0           embedding_country[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, None, 28)     0           embedding_city[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, None, 10)     0           embedding_mcc_category[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, None, 5)      0           embedding_day_of_week[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, None, 9)      0           embedding_hour[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, None, 15)     0           embedding_weekofyear[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, None, 6)      0           embedding_amnt[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, None, 9)      0           embedding_days_before[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, None, 6)      0           embedding_hour_diff[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, None, 182)    0           dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "                                                                 dropout_2[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "                                                                 dropout_4[0][0]                  \n",
      "                                                                 dropout_5[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "                                                                 dropout_7[0][0]                  \n",
      "                                                                 dropout_8[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "                                                                 dropout_10[0][0]                 \n",
      "                                                                 dropout_11[0][0]                 \n",
      "                                                                 dropout_12[0][0]                 \n",
      "                                                                 dropout_13[0][0]                 \n",
      "                                                                 dropout_14[0][0]                 \n",
      "                                                                 dropout_15[0][0]                 \n",
      "                                                                 dropout_16[0][0]                 \n",
      "                                                                 dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, None, 182)    0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_product (InputLayer)      [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, None, 256)    239616      dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_product (Embedding)   (None, 1, 4)         24          input_product[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 256)          0           bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d (GlobalMax (None, 256)          0           bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 4)            0           embedding_product[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 516)          0           global_average_pooling1d[0][0]   \n",
      "                                                                 global_max_pooling1d[0][0]       \n",
      "                                                                 reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 32)           16544       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            33          dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 270,647\n",
      "Trainable params: 270,647\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d39c54b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T05:06:34.927647Z",
     "iopub.status.busy": "2022-08-02T05:06:34.927045Z",
     "iopub.status.idle": "2022-08-02T06:41:23.617706Z",
     "shell.execute_reply": "2022-08-02T06:41:23.616666Z"
    },
    "papermill": {
     "duration": 5689.965672,
     "end_time": "2022-08-02T06:41:24.885251",
     "exception": false,
     "start_time": "2022-08-02T05:06:34.919579",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-02 05:06:39.799541: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-08-02 05:06:45.321494: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7270/7270 [==============================] - 391s 53ms/step - loss: 0.1090\n",
      "Validation ROC-AUC improved (-inf --> 0.774241).  Saving model ...\n",
      "Epoch 1 completed. Train roc-auc: 0.7772080672902142, Val roc-auc: 0.7742411038333016\n",
      "Starting epoch 2\n",
      "Epoch 2/2\n",
      "7270/7270 [==============================] - 385s 53ms/step - loss: 0.1046\n",
      "Validation ROC-AUC improved (0.774241 --> 0.780446).  Saving model ...\n",
      "Epoch 2 completed. Train roc-auc: 0.7868362179458909, Val roc-auc: 0.7804462457023869\n",
      "Starting epoch 3\n",
      "Epoch 3/3\n",
      "7270/7270 [==============================] - 386s 53ms/step - loss: 0.1031\n",
      "Validation ROC-AUC improved (0.780446 --> 0.782853).  Saving model ...\n",
      "Epoch 3 completed. Train roc-auc: 0.8026883791432717, Val roc-auc: 0.7828532263688749\n",
      "Starting epoch 4\n",
      "Epoch 4/4\n",
      "7270/7270 [==============================] - 394s 54ms/step - loss: 0.1016\n",
      "Validation ROC-AUC improved (0.782853 --> 0.786048).  Saving model ...\n",
      "Epoch 4 completed. Train roc-auc: 0.811780109018294, Val roc-auc: 0.7860483020141175\n",
      "Starting epoch 5\n",
      "Epoch 5/5\n",
      "7270/7270 [==============================] - 397s 55ms/step - loss: 0.1000\n",
      "No imporvement in Validation ROC-AUC. Current: 0.781152. Current best: 0.786048\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch 5 completed. Train roc-auc: 0.8248324847459738, Val roc-auc: 0.7811520265914695\n",
      "Starting epoch 6\n",
      "Epoch 6/6\n",
      "7270/7270 [==============================] - 390s 54ms/step - loss: 0.0982\n",
      "No imporvement in Validation ROC-AUC. Current: 0.775433. Current best: 0.786048\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Epoch 6 completed. Train roc-auc: 0.8360982781606192, Val roc-auc: 0.7754331721914883\n",
      "Starting epoch 7\n",
      "Epoch 7/7\n",
      "7270/7270 [==============================] - 383s 53ms/step - loss: 0.0963\n",
      "No imporvement in Validation ROC-AUC. Current: 0.769848. Current best: 0.786048\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping reached. Stop training...\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print(f'Starting epoch {epoch+1}')\n",
    "    train_epoch(model, dataset_train, batch_size=train_batch_size, shuffle=True, cur_epoch=epoch, \n",
    "                steps_per_epoch=7270)\n",
    "    \n",
    "    val_roc_auc = eval_model(model, dataset_val, batch_size=val_batch_szie)\n",
    "    model.save_weights(os.path.join(path_to_checkpoints, f'epoch_{epoch+1}_val_{val_roc_auc:.3f}.hdf5'))\n",
    "    \n",
    "    es(val_roc_auc, model)\n",
    "    \n",
    "    if es.early_stop:\n",
    "        print('Early stopping reached. Stop training...')\n",
    "        break\n",
    "        \n",
    "    train_roc_auc = eval_model(model, dataset_train, batch_size=val_batch_szie)\n",
    "    print(f'Epoch {epoch+1} completed. Train roc-auc: {train_roc_auc}, Val roc-auc: {val_roc_auc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5723.162187,
   "end_time": "2022-08-02T06:41:30.364978",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-08-02T05:06:07.202791",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
