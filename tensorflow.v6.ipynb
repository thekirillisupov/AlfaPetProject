{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9c70906",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-08-02T18:19:59.954543Z",
     "iopub.status.busy": "2022-08-02T18:19:59.954019Z",
     "iopub.status.idle": "2022-08-02T18:20:07.341839Z",
     "shell.execute_reply": "2022-08-02T18:20:07.340776Z"
    },
    "papermill": {
     "duration": 7.399635,
     "end_time": "2022-08-02T18:20:07.344484",
     "exception": false,
     "start_time": "2022-08-02T18:19:59.944849",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers as L\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ea60efb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T18:20:07.359414Z",
     "iopub.status.busy": "2022-08-02T18:20:07.358187Z",
     "iopub.status.idle": "2022-08-02T18:20:07.414109Z",
     "shell.execute_reply": "2022-08-02T18:20:07.413213Z"
    },
    "papermill": {
     "duration": 0.065318,
     "end_time": "2022-08-02T18:20:07.416269",
     "exception": false,
     "start_time": "2022-08-02T18:20:07.350951",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAIN_TRANSACTIONS_PATH = '../input/alfabattle2-sandbox/alfabattle2_sand_alfabattle2_train_transactions_contest/train_transactions_contest'\n",
    "TEST_TRANSACTIONS_PATH = '../input/alfabattle2-sandbox/alfabattle2_sand_alfabattle2_test_transactions_contest/test_transactions_contest'\n",
    "\n",
    "TRAIN_TARGET_PATH = '../input/alfabattle2-sandbox/alfabattle2_sand_alfabattle2_train_target.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4feafc8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T18:20:07.430174Z",
     "iopub.status.busy": "2022-08-02T18:20:07.429876Z",
     "iopub.status.idle": "2022-08-02T18:20:07.726992Z",
     "shell.execute_reply": "2022-08-02T18:20:07.725994Z"
    },
    "papermill": {
     "duration": 0.306915,
     "end_time": "2022-08-02T18:20:07.729529",
     "exception": false,
     "start_time": "2022-08-02T18:20:07.422614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_frame = pd.read_csv(TRAIN_TARGET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ded47242",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T18:20:07.745213Z",
     "iopub.status.busy": "2022-08-02T18:20:07.743663Z",
     "iopub.status.idle": "2022-08-02T18:20:07.804422Z",
     "shell.execute_reply": "2022-08-02T18:20:07.803532Z"
    },
    "papermill": {
     "duration": 0.070466,
     "end_time": "2022-08-02T18:20:07.806555",
     "exception": false,
     "start_time": "2022-08-02T18:20:07.736089",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_parquet_dataset_from_local(path_to_dataset: str, start_from: int = 0,\n",
    "                                     num_parts_to_read: int = 2, columns=None, verbose=False) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    читает num_parts_to_read партиций, преобразует их к pd.DataFrame и возвращает\n",
    "    :param path_to_dataset: путь до директории с партициями\n",
    "    :param start_from: номер партиции, с которой начать чтение\n",
    "    :param num_parts_to_read: количество партиций, которые требуется прочитать\n",
    "    :param columns: список колонок, которые нужно прочитать из партиции\n",
    "    :return: pd.DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    res = []\n",
    "    dataset_paths = sorted([os.path.join(path_to_dataset, filename) for filename in os.listdir(path_to_dataset) \n",
    "                              if filename.startswith('part')])\n",
    "    \n",
    "    start_from = max(0, start_from)\n",
    "    chunks = dataset_paths[start_from: start_from + num_parts_to_read]\n",
    "    if verbose:\n",
    "        print('Reading chunks:\\n')\n",
    "        for chunk in chunks:\n",
    "            print(chunk)\n",
    "    for chunk_path in tqdm_notebook(chunks, desc=\"Reading dataset with pandas\"):\n",
    "        chunk = pd.read_parquet(chunk_path,columns=columns)\n",
    "        res.append(chunk)\n",
    "    return pd.concat(res).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb99b070",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T18:20:07.820584Z",
     "iopub.status.busy": "2022-08-02T18:20:07.820315Z",
     "iopub.status.idle": "2022-08-02T18:20:07.882346Z",
     "shell.execute_reply": "2022-08-02T18:20:07.881452Z"
    },
    "papermill": {
     "duration": 0.071663,
     "end_time": "2022-08-02T18:20:07.884462",
     "exception": false,
     "start_time": "2022-08-02T18:20:07.812799",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "features = ['currency', 'operation_kind', 'card_type', 'operation_type', 'operation_type_group', 'ecommerce_flag',\n",
    "            'payment_system', 'income_flag', 'mcc', 'country', 'city', 'mcc_category', 'day_of_week',\n",
    "            'hour', 'weekofyear', 'amnt', 'days_before', 'hour_diff']\n",
    "\n",
    "def pad_sequence(array, max_len) -> np.array:\n",
    "    \"\"\"\n",
    "    принимает список списков (array) и делает padding каждого вложенного списка до max_len\n",
    "    :param array: список списков\n",
    "    :param max_len: максимальная длина до которой нужно сделать padding\n",
    "    :return: np.array после padding каждого вложенного списка до одинаковой длины\n",
    "    \"\"\"\n",
    "    add_zeros = max_len - len(array[0])\n",
    "    return np.array([list(x) + [0] * add_zeros for x in array])\n",
    "\n",
    "\n",
    "def truncate(x, num_last_transactions=750):\n",
    "    return x.values.transpose()[:, -num_last_transactions:].tolist()\n",
    "\n",
    "\n",
    "def transform_transactions_to_sequences(transactions_frame: pd.DataFrame,\n",
    "                                        num_last_transactions=750) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    принимает frame с транзакциями клиентов, сортирует транзакции по клиентам\n",
    "    (внутри клиента сортирует транзакции по возрастанию), берет num_last_transactions танзакций,\n",
    "    возвращает новый pd.DataFrame с двумя колонками: app_id и sequences.\n",
    "    каждое значение в колонке sequences - это список списков.\n",
    "    каждый список - значение одного конкретного признака во всех клиентских транзакциях.\n",
    "    Всего признаков len(features), поэтому будет len(features) списков.\n",
    "    Данная функция крайне полезна для подготовки датасета для работы с нейронными сетями.\n",
    "    :param transactions_frame: фрейм с транзакциями клиентов\n",
    "    :param num_last_transactions: количество транзакций клиента, которые будут рассмотрены\n",
    "    :return: pd.DataFrame из двух колонок (app_id, sequences)\n",
    "    \"\"\"\n",
    "    return transactions_frame \\\n",
    "        .sort_values(['app_id', 'transaction_number']) \\\n",
    "        .groupby(['app_id'])[features] \\\n",
    "        .apply(lambda x: truncate(x, num_last_transactions=num_last_transactions)) \\\n",
    "        .reset_index().rename(columns={0: 'sequences'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0df28694",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T18:20:07.897979Z",
     "iopub.status.busy": "2022-08-02T18:20:07.897688Z",
     "iopub.status.idle": "2022-08-02T18:20:07.958362Z",
     "shell.execute_reply": "2022-08-02T18:20:07.957416Z"
    },
    "papermill": {
     "duration": 0.069618,
     "end_time": "2022-08-02T18:20:07.960290",
     "exception": false,
     "start_time": "2022-08-02T18:20:07.890672",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_padded_buckets(frame_of_sequences: pd.DataFrame, bucket_info: Dict[int, int],\n",
    "                          save_to_file_path=None, has_target=True):\n",
    "    \"\"\"\n",
    "    Функция реализует sequence_bucketing технику для обучения нейронных сетей.\n",
    "    Принимает на вход frame_of_sequences (результат работы функции transform_transactions_to_sequences),\n",
    "    словарь bucket_info, где для последовательности каждой длины указано, до какой максимальной длины нужно делать\n",
    "    padding, далее группирует транзакции по бакетам (на основе длины), делает padding транзакций и сохраняет результат\n",
    "    в pickle файл, если нужно\n",
    "    :param frame_of_sequences: pd.DataFrame c транзакциями (результат применения transform_transactions_to_sequences)\n",
    "    :param bucket_info: словарь, где для последовательности каждой длины указано, до какой максимальной длины нужно делать\n",
    "    padding\n",
    "    :param save_to_file_path: опциональный путь до файла, куда нужно сохранить результат\n",
    "    :param has_target: флаг, есть ли в frame_of_sequences целевая переменная или нет. Если есть, то\n",
    "    будет записано в результат\n",
    "    :return: возвращает словарь с следюущими ключами (padded_sequences, targets, app_id, products)\n",
    "    \"\"\"\n",
    "    frame_of_sequences['bucket_idx'] = frame_of_sequences.sequence_length.map(bucket_info)\n",
    "    padded_seq = []\n",
    "    targets = []\n",
    "    app_ids = []\n",
    "    products = []\n",
    "\n",
    "    for size, bucket in frame_of_sequences.groupby('bucket_idx'):\n",
    "        padded_sequences = bucket.sequences.apply(lambda x: pad_sequence(x, size)).values\n",
    "        padded_sequences = np.array([np.array(x) for x in padded_sequences])\n",
    "        padded_seq.append(padded_sequences)\n",
    "\n",
    "        if has_target:\n",
    "            targets.append(bucket.flag.values)\n",
    "\n",
    "        app_ids.append(bucket.app_id.values)\n",
    "        products.append(bucket['product'].values)\n",
    "\n",
    "    frame_of_sequences.drop(columns=['bucket_idx'], inplace=True)\n",
    "\n",
    "    dict_result = {\n",
    "        'padded_sequences': np.array(padded_seq, dtype=object),\n",
    "        'targets': np.array(targets, dtype=object) if targets else [],\n",
    "        'app_id': np.array(app_ids, dtype=object),\n",
    "        'products': np.array(products, dtype=object),\n",
    "    }\n",
    "\n",
    "    if save_to_file_path:\n",
    "        with open(save_to_file_path, 'wb') as f:\n",
    "            pickle.dump(dict_result, f)\n",
    "    return dict_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9764387",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T18:20:07.973673Z",
     "iopub.status.busy": "2022-08-02T18:20:07.973402Z",
     "iopub.status.idle": "2022-08-02T18:20:08.045149Z",
     "shell.execute_reply": "2022-08-02T18:20:08.044369Z"
    },
    "papermill": {
     "duration": 0.080711,
     "end_time": "2022-08-02T18:20:08.047073",
     "exception": false,
     "start_time": "2022-08-02T18:20:07.966362",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../input/alfabattle2-sandbox/constants_for_rnn/constants_for_rnn/buckets_info.pkl', 'rb') as f:\n",
    "    mapping_seq_len_to_padded_len = pickle.load(f)\n",
    "    \n",
    "with open('../input/alfabattle2-sandbox/constants_for_rnn/constants_for_rnn/dense_features_buckets.pkl', 'rb') as f:\n",
    "    dense_features_buckets = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd132f46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T18:20:08.060541Z",
     "iopub.status.busy": "2022-08-02T18:20:08.060280Z",
     "iopub.status.idle": "2022-08-02T18:20:08.117025Z",
     "shell.execute_reply": "2022-08-02T18:20:08.116184Z"
    },
    "papermill": {
     "duration": 0.065655,
     "end_time": "2022-08-02T18:20:08.118933",
     "exception": false,
     "start_time": "2022-08-02T18:20:08.053278",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_buckets_from_transactions(path_to_dataset, save_to_path, frame_with_ids = None, \n",
    "                                     num_parts_to_preprocess_at_once: int = 1, \n",
    "                                     num_parts_total=50, has_target=False):\n",
    "    block = 0\n",
    "    for step in tqdm(range(0, num_parts_total, num_parts_to_preprocess_at_once), \n",
    "                                   desc=\"Transforming transactions data\"):\n",
    "        transactions_frame = read_parquet_dataset_from_local(path_to_dataset, step, num_parts_to_preprocess_at_once, \n",
    "                                                             verbose=True)\n",
    "        for dense_col in ['amnt', 'days_before', 'hour_diff']:\n",
    "            transactions_frame[dense_col] = np.digitize(transactions_frame[dense_col], bins=dense_features_buckets[dense_col])\n",
    "            \n",
    "        seq = transform_transactions_to_sequences(transactions_frame)\n",
    "        seq['sequence_length'] = seq.sequences.apply(lambda x: len(x[1]))\n",
    "        \n",
    "        if frame_with_ids is not None:\n",
    "            seq = seq.merge(frame_with_ids, on='app_id')\n",
    "\n",
    "        block_as_str = str(block)\n",
    "        if len(block_as_str) == 1:\n",
    "            block_as_str = '00' + block_as_str\n",
    "        else:\n",
    "            block_as_str = '0' + block_as_str\n",
    "            how\n",
    "        processed_fragment =  create_padded_buckets(seq, mapping_seq_len_to_padded_len, has_target=has_target, \n",
    "                                                    save_to_file_path=os.path.join(save_to_path, \n",
    "                                                                                   f'processed_chunk_{block_as_str}.pkl'))\n",
    "        block += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a12563b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T18:20:08.132857Z",
     "iopub.status.busy": "2022-08-02T18:20:08.132581Z",
     "iopub.status.idle": "2022-08-02T18:20:08.216948Z",
     "shell.execute_reply": "2022-08-02T18:20:08.215902Z"
    },
    "papermill": {
     "duration": 0.093581,
     "end_time": "2022-08-02T18:20:08.219380",
     "exception": false,
     "start_time": "2022-08-02T18:20:08.125799",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../input/train-val-buckets/val_buckets/processed_chunk_000.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_001.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_002.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_003.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_004.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_005.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_006.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_007.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_008.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_009.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_010.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_011.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_012.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_013.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_014.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_015.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_016.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_017.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_018.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_019.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_020.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_021.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_022.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_023.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_024.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_025.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_026.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_027.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_028.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_029.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_030.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_031.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_032.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_033.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_034.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_035.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_036.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_037.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_038.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_039.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_040.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_041.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_042.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_043.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_044.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_045.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_046.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_047.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_048.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_049.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_dataset = '../input/train-val-buckets/val_buckets'\n",
    "dir_with_datasets = os.listdir(path_to_dataset)\n",
    "dataset_val = sorted([os.path.join(path_to_dataset, x) for x in dir_with_datasets])\n",
    "dataset_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06110280",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T18:20:08.233995Z",
     "iopub.status.busy": "2022-08-02T18:20:08.232920Z",
     "iopub.status.idle": "2022-08-02T18:20:08.309144Z",
     "shell.execute_reply": "2022-08-02T18:20:08.308237Z"
    },
    "papermill": {
     "duration": 0.085327,
     "end_time": "2022-08-02T18:20:08.311143",
     "exception": false,
     "start_time": "2022-08-02T18:20:08.225816",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../input/train-val-buckets/train_buckets/processed_chunk_000.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_001.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_002.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_003.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_004.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_005.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_006.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_007.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_008.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_009.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_010.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_011.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_012.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_013.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_014.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_015.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_016.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_017.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_018.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_019.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_020.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_021.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_022.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_023.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_024.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_025.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_026.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_dataset = '../input/train-val-buckets/train_buckets'\n",
    "dir_with_datasets = os.listdir(path_to_dataset)\n",
    "dataset_train = sorted([os.path.join(path_to_dataset, x) for x in dir_with_datasets])\n",
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d62ed20e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T18:20:08.325798Z",
     "iopub.status.busy": "2022-08-02T18:20:08.324754Z",
     "iopub.status.idle": "2022-08-02T18:20:08.440771Z",
     "shell.execute_reply": "2022-08-02T18:20:08.438554Z"
    },
    "papermill": {
     "duration": 0.125658,
     "end_time": "2022-08-02T18:20:08.443187",
     "exception": false,
     "start_time": "2022-08-02T18:20:08.317529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6865b432",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T18:20:08.459586Z",
     "iopub.status.busy": "2022-08-02T18:20:08.458119Z",
     "iopub.status.idle": "2022-08-02T18:20:08.525044Z",
     "shell.execute_reply": "2022-08-02T18:20:08.524178Z"
    },
    "papermill": {
     "duration": 0.076508,
     "end_time": "2022-08-02T18:20:08.527123",
     "exception": false,
     "start_time": "2022-08-02T18:20:08.450615",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "transaction_features = ['currency', 'operation_kind', 'card_type', 'operation_type',\n",
    "                        'operation_type_group', 'ecommerce_flag', 'payment_system',\n",
    "                        'income_flag', 'mcc', 'country', 'city', 'mcc_category',\n",
    "                        'day_of_week', 'hour', 'weekofyear', 'amnt', 'days_before', 'hour_diff']\n",
    "\n",
    "def batches_generator(list_of_paths, batch_size=32, shuffle=False, is_infinite=False,\n",
    "                      verbose=False, device=None, output_format='tf', is_train=True):\n",
    "    \"\"\"\n",
    "    функция для создания батчей на вход для нейронной сети для моделей на keras и pytorch.\n",
    "    так же может использоваться как функция на стадии инференса\n",
    "    :param list_of_paths: путь до директории с предобработанными последовательностями\n",
    "    :param batch_size: размер батча\n",
    "    :param shuffle: флаг, если True, то перемешивает list_of_paths и так же\n",
    "    перемешивает последовательности внутри файла\n",
    "    :param is_infinite: флаг, если True,  то создает бесконечный генератор батчей\n",
    "    :param verbose: флаг, если True, то печатает текущий обрабатываемый файл\n",
    "    :param device: device на который положить данные, если работа на торче\n",
    "    :param output_format: допустимые варианты ['tf', 'torch']. Если 'torch', то возвращает словарь,\n",
    "    где ключи - батчи из признаков, таргетов и app_id. Если 'tf', то возвращает картеж: лист input-ов\n",
    "    для модели, и список таргетов.\n",
    "    :param is_train: флаг, Если True, то для кераса вернет (X, y), где X - input-ы в модель, а y - таргеты, \n",
    "    если False, то в y будут app_id; для torch вернет словарь с ключами на device.\n",
    "    :return: бачт из последовательностей и таргетов (или app_id)\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        if shuffle:\n",
    "            np.random.shuffle(list_of_paths)\n",
    "\n",
    "        for path in list_of_paths:\n",
    "            if verbose:\n",
    "                print(f'reading {path}')\n",
    "\n",
    "            with open(path, 'rb') as f:\n",
    "                '''\n",
    "                26.pkl is truncated \n",
    "                '''\n",
    "                if path == '../input/train-val-buckets/train_buckets/processed_chunk_026.pkl':\n",
    "                    continue\n",
    "                data = pickle.load(f)\n",
    "            padded_sequences, targets, products = data['padded_sequences'], data['targets'], data[\n",
    "                'products']\n",
    "            app_ids = data['app_id']\n",
    "            indices = np.arange(len(products))\n",
    "\n",
    "            if shuffle:\n",
    "                np.random.shuffle(indices)\n",
    "                padded_sequences = padded_sequences[indices]\n",
    "                targets = targets[indices]\n",
    "                products = products[indices]\n",
    "                app_ids = app_ids[indices]\n",
    "\n",
    "            for idx in range(len(products)):\n",
    "                bucket, product = padded_sequences[idx], products[idx]\n",
    "                app_id = app_ids[idx]\n",
    "                \n",
    "                if is_train:\n",
    "                    target = targets[idx]\n",
    "                \n",
    "                for jdx in range(0, len(bucket), batch_size):\n",
    "                    batch_sequences = bucket[jdx: jdx + batch_size]\n",
    "                    if is_train:\n",
    "                        batch_targets = target[jdx: jdx + batch_size]\n",
    "                    \n",
    "                    batch_products = product[jdx: jdx + batch_size]\n",
    "                    batch_app_ids = app_id[jdx: jdx + batch_size]\n",
    "                    \n",
    "                    if output_format == 'tf':\n",
    "                        batch_sequences = [batch_sequences[:, i] for i in\n",
    "                                           range(len(transaction_features))]\n",
    "                        \n",
    "                        # append product as input to tf model\n",
    "                        batch_sequences.append(batch_products)\n",
    "                        if is_train:\n",
    "                            yield batch_sequences, batch_targets\n",
    "                        else:\n",
    "                             yield batch_sequences, batch_app_ids\n",
    "                    else:\n",
    "                        batch_sequences = [torch.LongTensor(batch_sequences[:, i]).to(device)\n",
    "                                           for i in range(len(transaction_features))]\n",
    "                        if is_train:\n",
    "                            yield dict(transactions_features=batch_sequences,\n",
    "                                       product=torch.LongTensor(batch_products).to(device),\n",
    "                                       label=torch.LongTensor(batch_targets).to(device),\n",
    "                                       app_id=batch_app_ids)\n",
    "                        else:\n",
    "                            yield dict(transactions_features=batch_sequences,\n",
    "                                       product=torch.LongTensor(batch_products).to(device),\n",
    "                                       app_id=batch_app_ids)\n",
    "        if not is_infinite:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7163250",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T18:20:08.541050Z",
     "iopub.status.busy": "2022-08-02T18:20:08.540761Z",
     "iopub.status.idle": "2022-08-02T18:20:08.602115Z",
     "shell.execute_reply": "2022-08-02T18:20:08.601235Z"
    },
    "papermill": {
     "duration": 0.070882,
     "end_time": "2022-08-02T18:20:08.604174",
     "exception": false,
     "start_time": "2022-08-02T18:20:08.533292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation metric doesn't improve after a given patience.\"\"\"\n",
    "\n",
    "    def __init__(self, patience=7, mode='min', verbose=False, delta=0, save_path='checkpoint.hdf5', metric_name=None, save_format='tf'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            mode (str): One of ['min', 'max'], whether to maximize or minimaze the metric.\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            save_path (str): Path to saved model\n",
    "        \"\"\"\n",
    "        if mode not in ['min', 'max']:\n",
    "            raise ValueError(f'Unrecognized mode: {mode}!')\n",
    "\n",
    "        self.patience = patience\n",
    "        self.mode = mode\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.best_prev_score = np.Inf if mode == 'min' else -np.Inf\n",
    "        self.delta = delta\n",
    "        self.save_path = save_path\n",
    "        self.metric_name = 'metric' if not metric_name else metric_name\n",
    "        if save_format not in ['torch', 'tf']:\n",
    "            raise ValueError('Expected to save in one of the following formats: [\"torch\", \"tf\"]')\n",
    "        self.save_format = save_format\n",
    "        \n",
    "    def __call__(self, metric_value, model):\n",
    "\n",
    "        score = -metric_value if self.mode == 'min' else metric_value\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(metric_value, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(\n",
    "                f'No imporvement in Validation {self.metric_name}. Current: {score:.6f}. Current best: {self.best_score:.6f}')\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(metric_value, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, metric_value, model):\n",
    "        \"\"\"Saves model when validation loss decrease.\"\"\"\n",
    "        if self.verbose:\n",
    "            print(\n",
    "                f'Validation {self.metric_name} improved ({self.best_prev_score:.6f} --> {metric_value:.6f}).  Saving model ...')\n",
    "        if self.save_format == 'tf':\n",
    "            model.save_weights(self.save_path)\n",
    "        else:\n",
    "            torch.save(model.state_dict(), self.save_path)\n",
    "            \n",
    "        self.best_prev_score = metric_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59143ffb",
   "metadata": {
    "papermill": {
     "duration": 0.006115,
     "end_time": "2022-08-02T18:20:08.616738",
     "exception": false,
     "start_time": "2022-08-02T18:20:08.610623",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## TF-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3278dd50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T18:20:08.630250Z",
     "iopub.status.busy": "2022-08-02T18:20:08.629949Z",
     "iopub.status.idle": "2022-08-02T18:20:08.686901Z",
     "shell.execute_reply": "2022-08-02T18:20:08.686090Z"
    },
    "papermill": {
     "duration": 0.066025,
     "end_time": "2022-08-02T18:20:08.688905",
     "exception": false,
     "start_time": "2022-08-02T18:20:08.622880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, dataset_train, batch_size=64, shuffle=True, cur_epoch=0,\n",
    "                steps_per_epoch=5000, callbacks=None):\n",
    "    \"\"\"\n",
    "    функция обучения модели одну эпоху\n",
    "    :param model: tf.keras.Model\n",
    "    :param dataset_train: путь до директории с последовательностями\n",
    "    :param batch_size: размер батча\n",
    "    :param shuffle: флаг, если True, то перемешивает данные\n",
    "    :param cur_epoch:\n",
    "    :param steps_per_epoch:\n",
    "    :param callbacks: cписок из tf.keras.callbacks или None\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    train_generator = batches_generator(dataset_train, batch_size=batch_size, shuffle=shuffle,\n",
    "                                        output_format='tf', is_train=True)\n",
    "    model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=cur_epoch + 1,\n",
    "              initial_epoch=cur_epoch, callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "512a06f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T18:20:08.702846Z",
     "iopub.status.busy": "2022-08-02T18:20:08.702104Z",
     "iopub.status.idle": "2022-08-02T18:20:08.757132Z",
     "shell.execute_reply": "2022-08-02T18:20:08.756317Z"
    },
    "papermill": {
     "duration": 0.063981,
     "end_time": "2022-08-02T18:20:08.759092",
     "exception": false,
     "start_time": "2022-08-02T18:20:08.695111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval_model(model, dataset_val, batch_size=32) -> float:\n",
    "    \"\"\"\n",
    "    функция для оценки качества модели на отложенной выборке, возвращает roc-auc на валидационной\n",
    "    выборке\n",
    "    :param model: tf.keras.Model\n",
    "    :param dataset_val: путь до директории с последовательностями\n",
    "    :param batch_size: размер батча\n",
    "    :return: val roc-auc score\n",
    "    \"\"\"\n",
    "    val_generator = batches_generator(dataset_val, batch_size=batch_size, shuffle=False,\n",
    "                                      output_format='tf', is_train=True)\n",
    "    preds = model.predict(val_generator).flatten()\n",
    "    val_generator = batches_generator(dataset_val, batch_size=batch_size, shuffle=False,\n",
    "                                      output_format='tf', is_train=True)\n",
    "    targets = []\n",
    "    for _, y in val_generator:\n",
    "        targets.extend(y)\n",
    "\n",
    "    return roc_auc_score(targets, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cfa8a61c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T18:20:08.772653Z",
     "iopub.status.busy": "2022-08-02T18:20:08.772402Z",
     "iopub.status.idle": "2022-08-02T18:20:08.827246Z",
     "shell.execute_reply": "2022-08-02T18:20:08.826419Z"
    },
    "papermill": {
     "duration": 0.06389,
     "end_time": "2022-08-02T18:20:08.829167",
     "exception": false,
     "start_time": "2022-08-02T18:20:08.765277",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inference(model, dataset_test, batch_size=32) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    функция, которая делает предикты на новых данных, возвращает pd.DataFrame из двух колонок:\n",
    "    (app_id, score)\n",
    "    :param model: tf.keras.Model\n",
    "    :param dataset_test: путь до директории с последовательностями\n",
    "    :param batch_size: размер батча\n",
    "    :return: pd.DataFrame из двух колонок: (app_id, score)\n",
    "    \"\"\"\n",
    "    app_ids = []\n",
    "    test_generator = batches_generator(dataset_test, batch_size=batch_size, shuffle=False,\n",
    "                                       is_train=False, output_format='tf')\n",
    "    \n",
    "    preds = model.predict(test_generator).flatten()\n",
    "    \n",
    "    app_ids = []\n",
    "    test_generator = batches_generator(dataset_test, batch_size=batch_size, shuffle=False, \n",
    "                                       is_train=False, output_format='tf')\n",
    "    for _, y in test_generator:\n",
    "        app_ids.extend(y)\n",
    "        \n",
    "    return pd.DataFrame({\n",
    "        'app_id': app_ids,\n",
    "        'score': preds\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43c60f66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T18:20:08.842993Z",
     "iopub.status.busy": "2022-08-02T18:20:08.842717Z",
     "iopub.status.idle": "2022-08-02T18:20:08.906704Z",
     "shell.execute_reply": "2022-08-02T18:20:08.905843Z"
    },
    "papermill": {
     "duration": 0.073033,
     "end_time": "2022-08-02T18:20:08.908774",
     "exception": false,
     "start_time": "2022-08-02T18:20:08.835741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('../input/alfabattle2-sandbox/constants_for_rnn/constants_for_rnn/embedding_projections.pkl', 'rb') as f:\n",
    "    embedding_projections = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a5c03d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T18:20:08.922457Z",
     "iopub.status.busy": "2022-08-02T18:20:08.922189Z",
     "iopub.status.idle": "2022-08-02T18:20:08.981440Z",
     "shell.execute_reply": "2022-08-02T18:20:08.980609Z"
    },
    "papermill": {
     "duration": 0.068336,
     "end_time": "2022-08-02T18:20:08.983425",
     "exception": false,
     "start_time": "2022-08-02T18:20:08.915089",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transactions_rnn(transactions_cat_features, embedding_projections, product_col_name='product', \n",
    "                          rnn_units=128, classifier_units=32, optimizer=None):\n",
    "    if not optimizer:\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "        \n",
    "    inputs = []\n",
    "    cat_embeds = []\n",
    "    \n",
    "    for feature_name in transactions_cat_features:\n",
    "        inp = L.Input(shape=(None, ), dtype='uint32', name=f'input_{feature_name}')\n",
    "        inputs.append(inp)\n",
    "        source_size, projection = embedding_projections[feature_name]\n",
    "        emb = L.Embedding(source_size+1, projection, trainable=True, mask_zero=False, name=f'embedding_{feature_name}')(inp)\n",
    "        cat_embeds.append(emb)\n",
    "    \n",
    "    # product feature\n",
    "    inp = L.Input(shape=(1, ), dtype='uint32', name=f'input_product')\n",
    "    inputs.append(inp)\n",
    "    source_size, projection = embedding_projections['product']\n",
    "    product_emb = L.Embedding(source_size+1, projection, trainable=True, mask_zero=False, name=f'embedding_product')(inp)\n",
    "    product_emb_reshape = L.Reshape((projection, ))(product_emb)\n",
    "    \n",
    "    concated_cat_embeds = L.concatenate(cat_embeds)\n",
    "    \n",
    "    last_state = L.GRU(units=rnn_units)(concated_cat_embeds)\n",
    "    \n",
    "    combined_inp = L.concatenate([last_state, product_emb_reshape])\n",
    "    \n",
    "    dense_intermediate = L.Dense(classifier_units, activation='relu', )(combined_inp)\n",
    "    proba = L.Dense(1, activation='sigmoid')(dense_intermediate)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=proba)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71a815db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T18:20:08.997079Z",
     "iopub.status.busy": "2022-08-02T18:20:08.996794Z",
     "iopub.status.idle": "2022-08-02T18:20:09.057795Z",
     "shell.execute_reply": "2022-08-02T18:20:09.056995Z"
    },
    "papermill": {
     "duration": 0.070062,
     "end_time": "2022-08-02T18:20:09.059772",
     "exception": false,
     "start_time": "2022-08-02T18:20:08.989710",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bigru_pooling_model(transactions_cat_features, embedding_projections, product_col_name='product', \n",
    "                          rnn_units=128, classifier_units=32, optimizer=None):\n",
    "    if not optimizer:\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "        \n",
    "    inputs = []\n",
    "    cat_embeds = []\n",
    "    \n",
    "    for feature_name in transactions_cat_features:\n",
    "        inp = L.Input(shape=(None, ), dtype='uint32', name=f'input_{feature_name}')\n",
    "        inputs.append(inp)\n",
    "        source_size, projection = embedding_projections[feature_name]\n",
    "        emb = L.Embedding(source_size+1, projection, trainable=True, mask_zero=False, name=f'embedding_{feature_name}')(inp)\n",
    "        emb_dropout = L.Dropout(.3)(emb)\n",
    "        cat_embeds.append(emb_dropout)\n",
    "    \n",
    "    # product feature\n",
    "    inp = L.Input(shape=(1, ), dtype='uint32', name=f'input_product')\n",
    "    inputs.append(inp)\n",
    "    source_size, projection = embedding_projections['product']\n",
    "    product_emb = L.Embedding(source_size+1, projection, trainable=True, mask_zero=False, name=f'embedding_product')(inp)\n",
    "    product_emb_reshape = L.Reshape((projection, ))(product_emb)\n",
    "    \n",
    "    concated_cat_embeds = L.concatenate(cat_embeds)\n",
    "    dropout_embeds = L.Dropout(.3)(concated_cat_embeds)\n",
    "    \n",
    "    sequences = L.Bidirectional(L.LSTM(units=rnn_units, return_sequences=True))(dropout_embeds)\n",
    "    dropout_sequences = L.Dropout(.3)(sequences)\n",
    "    \n",
    "    pooled_avg_sequences = L.GlobalAveragePooling1D()(sequences)\n",
    "    pooled_max_sequences = L.GlobalMaxPooling1D()(sequences)\n",
    "    \n",
    "    concated = L.concatenate([pooled_avg_sequences, pooled_max_sequences, product_emb_reshape])\n",
    "    \n",
    "    dense_intermediate = L.Dense(classifier_units, activation='relu', \n",
    "                                 kernel_regularizer=keras.regularizers.L1L2(1e-7, 1e-5))(concated)\n",
    "    \n",
    "    proba = L.Dense(1, activation='sigmoid')(dense_intermediate)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=proba)\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52aad794",
   "metadata": {
    "papermill": {
     "duration": 0.006025,
     "end_time": "2022-08-02T18:20:09.071897",
     "exception": false,
     "start_time": "2022-08-02T18:20:09.065872",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35b0585e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T18:20:09.085411Z",
     "iopub.status.busy": "2022-08-02T18:20:09.085155Z",
     "iopub.status.idle": "2022-08-02T18:20:13.050806Z",
     "shell.execute_reply": "2022-08-02T18:20:13.049437Z"
    },
    "papermill": {
     "duration": 3.975655,
     "end_time": "2022-08-02T18:20:13.053791",
     "exception": false,
     "start_time": "2022-08-02T18:20:09.078136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove './rnn_baseline/checkpoints/pytorch_baseline': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "! mkdir ./rnn_baseline\n",
    "\n",
    "! mkdir ./rnn_baseline/checkpoints\n",
    "\n",
    "! rm -r ./rnn_baseline/checkpoints/pytorch_baseline\n",
    "! mkdir ./rnn_baseline/checkpoints/pytorch_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "230c3c48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T18:20:13.068731Z",
     "iopub.status.busy": "2022-08-02T18:20:13.068393Z",
     "iopub.status.idle": "2022-08-02T18:20:13.134474Z",
     "shell.execute_reply": "2022-08-02T18:20:13.133560Z"
    },
    "papermill": {
     "duration": 0.076467,
     "end_time": "2022-08-02T18:20:13.136938",
     "exception": false,
     "start_time": "2022-08-02T18:20:13.060471",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_to_checkpoints = './rnn_baseline/checkpoints/pytorch_baseline/'\n",
    "es = EarlyStopping(patience=4, mode='max', verbose=True, save_path=os.path.join(path_to_checkpoints, 'best_checkpoint.pt'), \n",
    "                   metric_name='ROC-AUC', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4daccee5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T18:20:13.151096Z",
     "iopub.status.busy": "2022-08-02T18:20:13.150790Z",
     "iopub.status.idle": "2022-08-02T18:20:13.205947Z",
     "shell.execute_reply": "2022-08-02T18:20:13.205095Z"
    },
    "papermill": {
     "duration": 0.064466,
     "end_time": "2022-08-02T18:20:13.208054",
     "exception": false,
     "start_time": "2022-08-02T18:20:13.143588",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "train_batch_size = 128\n",
    "val_batch_szie = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "83c19b68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T18:20:13.221867Z",
     "iopub.status.busy": "2022-08-02T18:20:13.221598Z",
     "iopub.status.idle": "2022-08-02T18:20:19.108790Z",
     "shell.execute_reply": "2022-08-02T18:20:19.107808Z"
    },
    "papermill": {
     "duration": 5.896907,
     "end_time": "2022-08-02T18:20:19.111234",
     "exception": false,
     "start_time": "2022-08-02T18:20:13.214327",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-02 18:20:13.312492: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-02 18:20:13.313635: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-02 18:20:13.314329: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-02 18:20:13.315165: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-02 18:20:13.315464: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-02 18:20:13.316157: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-02 18:20:13.316797: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-02 18:20:18.128358: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-02 18:20:18.129267: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-02 18:20:18.129915: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-02 18:20:18.130501: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15047 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    }
   ],
   "source": [
    "lr_scheduler = keras.optimizers.schedules.ExponentialDecay(\n",
    "    1e-3,\n",
    "    decay_steps=1000,\n",
    "    decay_rate=0.98,\n",
    "    staircase=True)\n",
    "\n",
    "model = bigru_pooling_model(transaction_features, embedding_projections, optimizer=keras.optimizers.Adam(learning_rate=lr_scheduler))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1126c346",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T18:20:19.125775Z",
     "iopub.status.busy": "2022-08-02T18:20:19.125493Z",
     "iopub.status.idle": "2022-08-02T18:20:19.186904Z",
     "shell.execute_reply": "2022-08-02T18:20:19.186028Z"
    },
    "papermill": {
     "duration": 0.072963,
     "end_time": "2022-08-02T18:20:19.191006",
     "exception": false,
     "start_time": "2022-08-02T18:20:19.118043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_currency (InputLayer)     [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_operation_kind (InputLaye [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_card_type (InputLayer)    [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_operation_type (InputLaye [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_operation_type_group (Inp [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_ecommerce_flag (InputLaye [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_payment_system (InputLaye [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_income_flag (InputLayer)  [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_mcc (InputLayer)          [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_country (InputLayer)      [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_city (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_mcc_category (InputLayer) [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_day_of_week (InputLayer)  [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_hour (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_weekofyear (InputLayer)   [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_amnt (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_days_before (InputLayer)  [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_hour_diff (InputLayer)    [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_currency (Embedding)  (None, None, 6)      72          input_currency[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "embedding_operation_kind (Embed (None, None, 5)      40          input_operation_kind[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_card_type (Embedding) (None, None, 29)     5104        input_card_type[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_operation_type (Embed (None, None, 9)      207         input_operation_type[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_operation_type_group  (None, None, 3)      15          input_operation_type_group[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "embedding_ecommerce_flag (Embed (None, None, 3)      12          input_ecommerce_flag[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_payment_system (Embed (None, None, 5)      40          input_payment_system[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_income_flag (Embeddin (None, None, 3)      12          input_income_flag[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "embedding_mcc (Embedding)       (None, None, 22)     2398        input_mcc[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_country (Embedding)   (None, None, 9)      225         input_country[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "embedding_city (Embedding)      (None, None, 28)     4592        input_city[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_mcc_category (Embeddi (None, None, 10)     290         input_mcc_category[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_day_of_week (Embeddin (None, None, 5)      40          input_day_of_week[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "embedding_hour (Embedding)      (None, None, 9)      225         input_hour[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_weekofyear (Embedding (None, None, 15)     810         input_weekofyear[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "embedding_amnt (Embedding)      (None, None, 6)      66          input_amnt[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_days_before (Embeddin (None, None, 9)      216         input_days_before[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "embedding_hour_diff (Embedding) (None, None, 6)      66          input_hour_diff[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, None, 6)      0           embedding_currency[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, None, 5)      0           embedding_operation_kind[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, None, 29)     0           embedding_card_type[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, None, 9)      0           embedding_operation_type[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, None, 3)      0           embedding_operation_type_group[0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, None, 3)      0           embedding_ecommerce_flag[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, None, 5)      0           embedding_payment_system[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, None, 3)      0           embedding_income_flag[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, None, 22)     0           embedding_mcc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, None, 9)      0           embedding_country[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, None, 28)     0           embedding_city[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, None, 10)     0           embedding_mcc_category[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, None, 5)      0           embedding_day_of_week[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, None, 9)      0           embedding_hour[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, None, 15)     0           embedding_weekofyear[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, None, 6)      0           embedding_amnt[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, None, 9)      0           embedding_days_before[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, None, 6)      0           embedding_hour_diff[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, None, 182)    0           dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "                                                                 dropout_2[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "                                                                 dropout_4[0][0]                  \n",
      "                                                                 dropout_5[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "                                                                 dropout_7[0][0]                  \n",
      "                                                                 dropout_8[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "                                                                 dropout_10[0][0]                 \n",
      "                                                                 dropout_11[0][0]                 \n",
      "                                                                 dropout_12[0][0]                 \n",
      "                                                                 dropout_13[0][0]                 \n",
      "                                                                 dropout_14[0][0]                 \n",
      "                                                                 dropout_15[0][0]                 \n",
      "                                                                 dropout_16[0][0]                 \n",
      "                                                                 dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, None, 182)    0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_product (InputLayer)      [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, None, 256)    318464      dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_product (Embedding)   (None, 1, 4)         24          input_product[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 256)          0           bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d (GlobalMax (None, 256)          0           bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 4)            0           embedding_product[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 516)          0           global_average_pooling1d[0][0]   \n",
      "                                                                 global_max_pooling1d[0][0]       \n",
      "                                                                 reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 32)           16544       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            33          dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 349,495\n",
      "Trainable params: 349,495\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a1d1b7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T18:20:19.206336Z",
     "iopub.status.busy": "2022-08-02T18:20:19.206062Z",
     "iopub.status.idle": "2022-08-02T18:20:19.262507Z",
     "shell.execute_reply": "2022-08-02T18:20:19.261478Z"
    },
    "papermill": {
     "duration": 0.066604,
     "end_time": "2022-08-02T18:20:19.264708",
     "exception": false,
     "start_time": "2022-08-02T18:20:19.198104",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../input/train-val-buckets/train_buckets/processed_chunk_000.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_001.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_002.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_003.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_004.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_005.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_006.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_007.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_008.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_009.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_010.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_011.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_012.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_013.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_014.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_015.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_016.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_017.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_018.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_019.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_020.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_021.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_022.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_023.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_024.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_025.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_026.pkl']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "10fb5671",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T18:20:19.279510Z",
     "iopub.status.busy": "2022-08-02T18:20:19.279251Z",
     "iopub.status.idle": "2022-08-02T19:56:09.361314Z",
     "shell.execute_reply": "2022-08-02T19:56:09.360277Z"
    },
    "papermill": {
     "duration": 5751.414803,
     "end_time": "2022-08-02T19:56:10.686354",
     "exception": false,
     "start_time": "2022-08-02T18:20:19.271551",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-02 18:20:24.016507: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-08-02 18:20:29.532038: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7270/7270 [==============================] - 410s 55ms/step - loss: 0.1105\n",
      "Validation ROC-AUC improved (-inf --> 0.765486).  Saving model ...\n",
      "Epoch 1 completed. Train roc-auc: 0.7643314886802222, Val roc-auc: 0.7654859373142129\n",
      "Starting epoch 2\n",
      "Epoch 2/2\n",
      "7270/7270 [==============================] - 412s 57ms/step - loss: 0.1051\n",
      "Validation ROC-AUC improved (0.765486 --> 0.773396).  Saving model ...\n",
      "Epoch 2 completed. Train roc-auc: 0.7774393929270598, Val roc-auc: 0.7733955774477724\n",
      "Starting epoch 3\n",
      "Epoch 3/3\n",
      "7270/7270 [==============================] - 407s 56ms/step - loss: 0.1038\n",
      "Validation ROC-AUC improved (0.773396 --> 0.780670).  Saving model ...\n",
      "Epoch 3 completed. Train roc-auc: 0.7889369061980601, Val roc-auc: 0.780669619814717\n",
      "Starting epoch 4\n",
      "Epoch 4/4\n",
      "7270/7270 [==============================] - 414s 57ms/step - loss: 0.1028\n",
      "No imporvement in Validation ROC-AUC. Current: 0.779028. Current best: 0.780670\n",
      "EarlyStopping counter: 1 out of 4\n",
      "Epoch 4 completed. Train roc-auc: 0.7937360170977369, Val roc-auc: 0.7790278455478926\n",
      "Starting epoch 5\n",
      "Epoch 5/5\n",
      "7270/7270 [==============================] - 396s 54ms/step - loss: 0.1020\n",
      "No imporvement in Validation ROC-AUC. Current: 0.779158. Current best: 0.780670\n",
      "EarlyStopping counter: 2 out of 4\n",
      "Epoch 5 completed. Train roc-auc: 0.7985049402506665, Val roc-auc: 0.7791575616962025\n",
      "Starting epoch 6\n",
      "Epoch 6/6\n",
      "7270/7270 [==============================] - 402s 55ms/step - loss: 0.1012\n",
      "No imporvement in Validation ROC-AUC. Current: 0.776889. Current best: 0.780670\n",
      "EarlyStopping counter: 3 out of 4\n",
      "Epoch 6 completed. Train roc-auc: 0.8021924602717712, Val roc-auc: 0.776889204715983\n",
      "Starting epoch 7\n",
      "Epoch 7/7\n",
      "7270/7270 [==============================] - 400s 55ms/step - loss: 0.1005\n",
      "No imporvement in Validation ROC-AUC. Current: 0.779734. Current best: 0.780670\n",
      "EarlyStopping counter: 4 out of 4\n",
      "Early stopping reached. Stop training...\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print(f'Starting epoch {epoch+1}')\n",
    "    \n",
    "    train_epoch(model, dataset_train, batch_size=train_batch_size, shuffle=True, cur_epoch=epoch, \n",
    "                steps_per_epoch=7270)\n",
    "    \n",
    "    val_roc_auc = eval_model(model, dataset_val, batch_size=val_batch_szie)\n",
    "    model.save_weights(os.path.join(path_to_checkpoints, f'epoch_{epoch+1}_val_{val_roc_auc:.3f}.hdf5'))\n",
    "    \n",
    "    es(val_roc_auc, model)\n",
    "    \n",
    "    if es.early_stop:\n",
    "        print('Early stopping reached. Stop training...')\n",
    "        break\n",
    "        \n",
    "    train_roc_auc = eval_model(model, dataset_train, batch_size=val_batch_szie)\n",
    "    print(f'Epoch {epoch+1} completed. Train roc-auc: {train_roc_auc}, Val roc-auc: {val_roc_auc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5783.130856,
   "end_time": "2022-08-02T19:56:15.542268",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-08-02T18:19:52.411412",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
