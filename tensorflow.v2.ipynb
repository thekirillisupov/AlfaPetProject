{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5c8a81d",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-08-01T18:31:03.757495Z",
     "iopub.status.busy": "2022-08-01T18:31:03.756986Z",
     "iopub.status.idle": "2022-08-01T18:31:12.007501Z",
     "shell.execute_reply": "2022-08-01T18:31:12.006502Z"
    },
    "papermill": {
     "duration": 8.277796,
     "end_time": "2022-08-01T18:31:12.010191",
     "exception": false,
     "start_time": "2022-08-01T18:31:03.732395",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers as L\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "370f7a78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T18:31:12.030125Z",
     "iopub.status.busy": "2022-08-01T18:31:12.028169Z",
     "iopub.status.idle": "2022-08-01T18:31:12.092670Z",
     "shell.execute_reply": "2022-08-01T18:31:12.091776Z"
    },
    "papermill": {
     "duration": 0.075998,
     "end_time": "2022-08-01T18:31:12.094874",
     "exception": false,
     "start_time": "2022-08-01T18:31:12.018876",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAIN_TRANSACTIONS_PATH = '../input/alfabattle2-sandbox/alfabattle2_sand_alfabattle2_train_transactions_contest/train_transactions_contest'\n",
    "TEST_TRANSACTIONS_PATH = '../input/alfabattle2-sandbox/alfabattle2_sand_alfabattle2_test_transactions_contest/test_transactions_contest'\n",
    "\n",
    "TRAIN_TARGET_PATH = '../input/alfabattle2-sandbox/alfabattle2_sand_alfabattle2_train_target.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2df51ccf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T18:31:12.113224Z",
     "iopub.status.busy": "2022-08-01T18:31:12.112931Z",
     "iopub.status.idle": "2022-08-01T18:31:12.499152Z",
     "shell.execute_reply": "2022-08-01T18:31:12.498169Z"
    },
    "papermill": {
     "duration": 0.399123,
     "end_time": "2022-08-01T18:31:12.502321",
     "exception": false,
     "start_time": "2022-08-01T18:31:12.103198",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_frame = pd.read_csv(TRAIN_TARGET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e991777",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T18:31:12.521080Z",
     "iopub.status.busy": "2022-08-01T18:31:12.520762Z",
     "iopub.status.idle": "2022-08-01T18:31:12.588799Z",
     "shell.execute_reply": "2022-08-01T18:31:12.587958Z"
    },
    "papermill": {
     "duration": 0.079563,
     "end_time": "2022-08-01T18:31:12.590984",
     "exception": false,
     "start_time": "2022-08-01T18:31:12.511421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_parquet_dataset_from_local(path_to_dataset: str, start_from: int = 0,\n",
    "                                     num_parts_to_read: int = 2, columns=None, verbose=False) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    читает num_parts_to_read партиций, преобразует их к pd.DataFrame и возвращает\n",
    "    :param path_to_dataset: путь до директории с партициями\n",
    "    :param start_from: номер партиции, с которой начать чтение\n",
    "    :param num_parts_to_read: количество партиций, которые требуется прочитать\n",
    "    :param columns: список колонок, которые нужно прочитать из партиции\n",
    "    :return: pd.DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    res = []\n",
    "    dataset_paths = sorted([os.path.join(path_to_dataset, filename) for filename in os.listdir(path_to_dataset) \n",
    "                              if filename.startswith('part')])\n",
    "    \n",
    "    start_from = max(0, start_from)\n",
    "    chunks = dataset_paths[start_from: start_from + num_parts_to_read]\n",
    "    if verbose:\n",
    "        print('Reading chunks:\\n')\n",
    "        for chunk in chunks:\n",
    "            print(chunk)\n",
    "    for chunk_path in tqdm_notebook(chunks, desc=\"Reading dataset with pandas\"):\n",
    "        chunk = pd.read_parquet(chunk_path,columns=columns)\n",
    "        res.append(chunk)\n",
    "    return pd.concat(res).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2eb4cbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T18:31:12.609668Z",
     "iopub.status.busy": "2022-08-01T18:31:12.609353Z",
     "iopub.status.idle": "2022-08-01T18:31:12.678050Z",
     "shell.execute_reply": "2022-08-01T18:31:12.677178Z"
    },
    "papermill": {
     "duration": 0.080642,
     "end_time": "2022-08-01T18:31:12.680190",
     "exception": false,
     "start_time": "2022-08-01T18:31:12.599548",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "features = ['currency', 'operation_kind', 'card_type', 'operation_type', 'operation_type_group', 'ecommerce_flag',\n",
    "            'payment_system', 'income_flag', 'mcc', 'country', 'city', 'mcc_category', 'day_of_week',\n",
    "            'hour', 'weekofyear', 'amnt', 'days_before', 'hour_diff']\n",
    "\n",
    "def pad_sequence(array, max_len) -> np.array:\n",
    "    \"\"\"\n",
    "    принимает список списков (array) и делает padding каждого вложенного списка до max_len\n",
    "    :param array: список списков\n",
    "    :param max_len: максимальная длина до которой нужно сделать padding\n",
    "    :return: np.array после padding каждого вложенного списка до одинаковой длины\n",
    "    \"\"\"\n",
    "    add_zeros = max_len - len(array[0])\n",
    "    return np.array([list(x) + [0] * add_zeros for x in array])\n",
    "\n",
    "\n",
    "def truncate(x, num_last_transactions=750):\n",
    "    return x.values.transpose()[:, -num_last_transactions:].tolist()\n",
    "\n",
    "\n",
    "def transform_transactions_to_sequences(transactions_frame: pd.DataFrame,\n",
    "                                        num_last_transactions=750) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    принимает frame с транзакциями клиентов, сортирует транзакции по клиентам\n",
    "    (внутри клиента сортирует транзакции по возрастанию), берет num_last_transactions танзакций,\n",
    "    возвращает новый pd.DataFrame с двумя колонками: app_id и sequences.\n",
    "    каждое значение в колонке sequences - это список списков.\n",
    "    каждый список - значение одного конкретного признака во всех клиентских транзакциях.\n",
    "    Всего признаков len(features), поэтому будет len(features) списков.\n",
    "    Данная функция крайне полезна для подготовки датасета для работы с нейронными сетями.\n",
    "    :param transactions_frame: фрейм с транзакциями клиентов\n",
    "    :param num_last_transactions: количество транзакций клиента, которые будут рассмотрены\n",
    "    :return: pd.DataFrame из двух колонок (app_id, sequences)\n",
    "    \"\"\"\n",
    "    return transactions_frame \\\n",
    "        .sort_values(['app_id', 'transaction_number']) \\\n",
    "        .groupby(['app_id'])[features] \\\n",
    "        .apply(lambda x: truncate(x, num_last_transactions=num_last_transactions)) \\\n",
    "        .reset_index().rename(columns={0: 'sequences'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcc8472d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T18:31:12.698164Z",
     "iopub.status.busy": "2022-08-01T18:31:12.697876Z",
     "iopub.status.idle": "2022-08-01T18:31:12.768252Z",
     "shell.execute_reply": "2022-08-01T18:31:12.767404Z"
    },
    "papermill": {
     "duration": 0.081951,
     "end_time": "2022-08-01T18:31:12.770454",
     "exception": false,
     "start_time": "2022-08-01T18:31:12.688503",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_padded_buckets(frame_of_sequences: pd.DataFrame, bucket_info: Dict[int, int],\n",
    "                          save_to_file_path=None, has_target=True):\n",
    "    \"\"\"\n",
    "    Функция реализует sequence_bucketing технику для обучения нейронных сетей.\n",
    "    Принимает на вход frame_of_sequences (результат работы функции transform_transactions_to_sequences),\n",
    "    словарь bucket_info, где для последовательности каждой длины указано, до какой максимальной длины нужно делать\n",
    "    padding, далее группирует транзакции по бакетам (на основе длины), делает padding транзакций и сохраняет результат\n",
    "    в pickle файл, если нужно\n",
    "    :param frame_of_sequences: pd.DataFrame c транзакциями (результат применения transform_transactions_to_sequences)\n",
    "    :param bucket_info: словарь, где для последовательности каждой длины указано, до какой максимальной длины нужно делать\n",
    "    padding\n",
    "    :param save_to_file_path: опциональный путь до файла, куда нужно сохранить результат\n",
    "    :param has_target: флаг, есть ли в frame_of_sequences целевая переменная или нет. Если есть, то\n",
    "    будет записано в результат\n",
    "    :return: возвращает словарь с следюущими ключами (padded_sequences, targets, app_id, products)\n",
    "    \"\"\"\n",
    "    frame_of_sequences['bucket_idx'] = frame_of_sequences.sequence_length.map(bucket_info)\n",
    "    padded_seq = []\n",
    "    targets = []\n",
    "    app_ids = []\n",
    "    products = []\n",
    "\n",
    "    for size, bucket in frame_of_sequences.groupby('bucket_idx'):\n",
    "        padded_sequences = bucket.sequences.apply(lambda x: pad_sequence(x, size)).values\n",
    "        padded_sequences = np.array([np.array(x) for x in padded_sequences])\n",
    "        padded_seq.append(padded_sequences)\n",
    "\n",
    "        if has_target:\n",
    "            targets.append(bucket.flag.values)\n",
    "\n",
    "        app_ids.append(bucket.app_id.values)\n",
    "        products.append(bucket['product'].values)\n",
    "\n",
    "    frame_of_sequences.drop(columns=['bucket_idx'], inplace=True)\n",
    "\n",
    "    dict_result = {\n",
    "        'padded_sequences': np.array(padded_seq, dtype=object),\n",
    "        'targets': np.array(targets, dtype=object) if targets else [],\n",
    "        'app_id': np.array(app_ids, dtype=object),\n",
    "        'products': np.array(products, dtype=object),\n",
    "    }\n",
    "\n",
    "    if save_to_file_path:\n",
    "        with open(save_to_file_path, 'wb') as f:\n",
    "            pickle.dump(dict_result, f)\n",
    "    return dict_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9312374c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T18:31:12.788427Z",
     "iopub.status.busy": "2022-08-01T18:31:12.788137Z",
     "iopub.status.idle": "2022-08-01T18:31:12.868707Z",
     "shell.execute_reply": "2022-08-01T18:31:12.867785Z"
    },
    "papermill": {
     "duration": 0.092012,
     "end_time": "2022-08-01T18:31:12.871017",
     "exception": false,
     "start_time": "2022-08-01T18:31:12.779005",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../input/alfabattle2-sandbox/constants_for_rnn/constants_for_rnn/buckets_info.pkl', 'rb') as f:\n",
    "    mapping_seq_len_to_padded_len = pickle.load(f)\n",
    "    \n",
    "with open('../input/alfabattle2-sandbox/constants_for_rnn/constants_for_rnn/dense_features_buckets.pkl', 'rb') as f:\n",
    "    dense_features_buckets = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "638dae8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T18:31:12.889485Z",
     "iopub.status.busy": "2022-08-01T18:31:12.889200Z",
     "iopub.status.idle": "2022-08-01T18:31:12.958014Z",
     "shell.execute_reply": "2022-08-01T18:31:12.957162Z"
    },
    "papermill": {
     "duration": 0.08066,
     "end_time": "2022-08-01T18:31:12.960274",
     "exception": false,
     "start_time": "2022-08-01T18:31:12.879614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_buckets_from_transactions(path_to_dataset, save_to_path, frame_with_ids = None, \n",
    "                                     num_parts_to_preprocess_at_once: int = 1, \n",
    "                                     num_parts_total=50, has_target=False):\n",
    "    block = 0\n",
    "    for step in tqdm(range(0, num_parts_total, num_parts_to_preprocess_at_once), \n",
    "                                   desc=\"Transforming transactions data\"):\n",
    "        transactions_frame = read_parquet_dataset_from_local(path_to_dataset, step, num_parts_to_preprocess_at_once, \n",
    "                                                             verbose=True)\n",
    "        for dense_col in ['amnt', 'days_before', 'hour_diff']:\n",
    "            transactions_frame[dense_col] = np.digitize(transactions_frame[dense_col], bins=dense_features_buckets[dense_col])\n",
    "            \n",
    "        seq = transform_transactions_to_sequences(transactions_frame)\n",
    "        seq['sequence_length'] = seq.sequences.apply(lambda x: len(x[1]))\n",
    "        \n",
    "        if frame_with_ids is not None:\n",
    "            seq = seq.merge(frame_with_ids, on='app_id')\n",
    "\n",
    "        block_as_str = str(block)\n",
    "        if len(block_as_str) == 1:\n",
    "            block_as_str = '00' + block_as_str\n",
    "        else:\n",
    "            block_as_str = '0' + block_as_str\n",
    "            how\n",
    "        processed_fragment =  create_padded_buckets(seq, mapping_seq_len_to_padded_len, has_target=has_target, \n",
    "                                                    save_to_file_path=os.path.join(save_to_path, \n",
    "                                                                                   f'processed_chunk_{block_as_str}.pkl'))\n",
    "        block += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4a35311",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T18:31:12.978038Z",
     "iopub.status.busy": "2022-08-01T18:31:12.977755Z",
     "iopub.status.idle": "2022-08-01T18:31:13.317088Z",
     "shell.execute_reply": "2022-08-01T18:31:13.315999Z"
    },
    "papermill": {
     "duration": 0.352252,
     "end_time": "2022-08-01T18:31:13.320727",
     "exception": false,
     "start_time": "2022-08-01T18:31:12.968475",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../input/train-val-buckets/val_buckets/processed_chunk_000.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_001.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_002.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_003.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_004.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_005.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_006.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_007.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_008.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_009.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_010.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_011.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_012.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_013.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_014.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_015.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_016.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_017.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_018.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_019.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_020.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_021.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_022.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_023.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_024.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_025.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_026.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_027.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_028.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_029.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_030.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_031.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_032.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_033.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_034.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_035.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_036.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_037.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_038.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_039.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_040.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_041.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_042.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_043.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_044.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_045.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_046.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_047.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_048.pkl',\n",
       " '../input/train-val-buckets/val_buckets/processed_chunk_049.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_dataset = '../input/train-val-buckets/val_buckets'\n",
    "dir_with_datasets = os.listdir(path_to_dataset)\n",
    "dataset_val = sorted([os.path.join(path_to_dataset, x) for x in dir_with_datasets])\n",
    "dataset_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6cd8c39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T18:31:13.340319Z",
     "iopub.status.busy": "2022-08-01T18:31:13.340013Z",
     "iopub.status.idle": "2022-08-01T18:31:13.584045Z",
     "shell.execute_reply": "2022-08-01T18:31:13.583006Z"
    },
    "papermill": {
     "duration": 0.25613,
     "end_time": "2022-08-01T18:31:13.586825",
     "exception": false,
     "start_time": "2022-08-01T18:31:13.330695",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../input/train-val-buckets/train_buckets/processed_chunk_000.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_001.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_002.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_003.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_004.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_005.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_006.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_007.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_008.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_009.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_010.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_011.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_012.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_013.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_014.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_015.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_016.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_017.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_018.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_019.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_020.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_021.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_022.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_023.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_024.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_025.pkl',\n",
       " '../input/train-val-buckets/train_buckets/processed_chunk_026.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_dataset = '../input/train-val-buckets/train_buckets'\n",
    "dir_with_datasets = os.listdir(path_to_dataset)\n",
    "dataset_train = sorted([os.path.join(path_to_dataset, x) for x in dir_with_datasets])\n",
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc70f9c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T18:31:13.605136Z",
     "iopub.status.busy": "2022-08-01T18:31:13.604844Z",
     "iopub.status.idle": "2022-08-01T18:31:13.732597Z",
     "shell.execute_reply": "2022-08-01T18:31:13.731116Z"
    },
    "papermill": {
     "duration": 0.139285,
     "end_time": "2022-08-01T18:31:13.734747",
     "exception": false,
     "start_time": "2022-08-01T18:31:13.595462",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79db5dc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T18:31:13.755680Z",
     "iopub.status.busy": "2022-08-01T18:31:13.755357Z",
     "iopub.status.idle": "2022-08-01T18:31:13.834352Z",
     "shell.execute_reply": "2022-08-01T18:31:13.833520Z"
    },
    "papermill": {
     "duration": 0.091439,
     "end_time": "2022-08-01T18:31:13.836541",
     "exception": false,
     "start_time": "2022-08-01T18:31:13.745102",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "transaction_features = ['currency', 'operation_kind', 'card_type', 'operation_type',\n",
    "                        'operation_type_group', 'ecommerce_flag', 'payment_system',\n",
    "                        'income_flag', 'mcc', 'country', 'city', 'mcc_category',\n",
    "                        'day_of_week', 'hour', 'weekofyear', 'amnt', 'days_before', 'hour_diff']\n",
    "\n",
    "def batches_generator(list_of_paths, batch_size=32, shuffle=False, is_infinite=False,\n",
    "                      verbose=False, device=None, output_format='tf', is_train=True):\n",
    "    \"\"\"\n",
    "    функция для создания батчей на вход для нейронной сети для моделей на keras и pytorch.\n",
    "    так же может использоваться как функция на стадии инференса\n",
    "    :param list_of_paths: путь до директории с предобработанными последовательностями\n",
    "    :param batch_size: размер батча\n",
    "    :param shuffle: флаг, если True, то перемешивает list_of_paths и так же\n",
    "    перемешивает последовательности внутри файла\n",
    "    :param is_infinite: флаг, если True,  то создает бесконечный генератор батчей\n",
    "    :param verbose: флаг, если True, то печатает текущий обрабатываемый файл\n",
    "    :param device: device на который положить данные, если работа на торче\n",
    "    :param output_format: допустимые варианты ['tf', 'torch']. Если 'torch', то возвращает словарь,\n",
    "    где ключи - батчи из признаков, таргетов и app_id. Если 'tf', то возвращает картеж: лист input-ов\n",
    "    для модели, и список таргетов.\n",
    "    :param is_train: флаг, Если True, то для кераса вернет (X, y), где X - input-ы в модель, а y - таргеты, \n",
    "    если False, то в y будут app_id; для torch вернет словарь с ключами на device.\n",
    "    :return: бачт из последовательностей и таргетов (или app_id)\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        if shuffle:\n",
    "            np.random.shuffle(list_of_paths)\n",
    "\n",
    "        for path in list_of_paths:\n",
    "            if verbose:\n",
    "                print(f'reading {path}')\n",
    "\n",
    "            with open(path, 'rb') as f:\n",
    "                '''\n",
    "                26.pkl is truncated \n",
    "                '''\n",
    "                if path == '../input/train-val-buckets/train_buckets/processed_chunk_026.pkl':\n",
    "                    continue\n",
    "                data = pickle.load(f)\n",
    "            padded_sequences, targets, products = data['padded_sequences'], data['targets'], data[\n",
    "                'products']\n",
    "            app_ids = data['app_id']\n",
    "            indices = np.arange(len(products))\n",
    "\n",
    "            if shuffle:\n",
    "                np.random.shuffle(indices)\n",
    "                padded_sequences = padded_sequences[indices]\n",
    "                targets = targets[indices]\n",
    "                products = products[indices]\n",
    "                app_ids = app_ids[indices]\n",
    "\n",
    "            for idx in range(len(products)):\n",
    "                bucket, product = padded_sequences[idx], products[idx]\n",
    "                app_id = app_ids[idx]\n",
    "                \n",
    "                if is_train:\n",
    "                    target = targets[idx]\n",
    "                \n",
    "                for jdx in range(0, len(bucket), batch_size):\n",
    "                    batch_sequences = bucket[jdx: jdx + batch_size]\n",
    "                    if is_train:\n",
    "                        batch_targets = target[jdx: jdx + batch_size]\n",
    "                    \n",
    "                    batch_products = product[jdx: jdx + batch_size]\n",
    "                    batch_app_ids = app_id[jdx: jdx + batch_size]\n",
    "                    \n",
    "                    if output_format == 'tf':\n",
    "                        batch_sequences = [batch_sequences[:, i] for i in\n",
    "                                           range(len(transaction_features))]\n",
    "                        \n",
    "                        # append product as input to tf model\n",
    "                        batch_sequences.append(batch_products)\n",
    "                        if is_train:\n",
    "                            yield batch_sequences, batch_targets\n",
    "                        else:\n",
    "                             yield batch_sequences, batch_app_ids\n",
    "                    else:\n",
    "                        batch_sequences = [torch.LongTensor(batch_sequences[:, i]).to(device)\n",
    "                                           for i in range(len(transaction_features))]\n",
    "                        if is_train:\n",
    "                            yield dict(transactions_features=batch_sequences,\n",
    "                                       product=torch.LongTensor(batch_products).to(device),\n",
    "                                       label=torch.LongTensor(batch_targets).to(device),\n",
    "                                       app_id=batch_app_ids)\n",
    "                        else:\n",
    "                            yield dict(transactions_features=batch_sequences,\n",
    "                                       product=torch.LongTensor(batch_products).to(device),\n",
    "                                       app_id=batch_app_ids)\n",
    "        if not is_infinite:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a5c2360",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T18:31:13.855101Z",
     "iopub.status.busy": "2022-08-01T18:31:13.854816Z",
     "iopub.status.idle": "2022-08-01T18:31:13.926511Z",
     "shell.execute_reply": "2022-08-01T18:31:13.925648Z"
    },
    "papermill": {
     "duration": 0.083828,
     "end_time": "2022-08-01T18:31:13.928995",
     "exception": false,
     "start_time": "2022-08-01T18:31:13.845167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation metric doesn't improve after a given patience.\"\"\"\n",
    "\n",
    "    def __init__(self, patience=7, mode='min', verbose=False, delta=0, save_path='checkpoint.hdf5', metric_name=None, save_format='tf'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            mode (str): One of ['min', 'max'], whether to maximize or minimaze the metric.\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            save_path (str): Path to saved model\n",
    "        \"\"\"\n",
    "        if mode not in ['min', 'max']:\n",
    "            raise ValueError(f'Unrecognized mode: {mode}!')\n",
    "\n",
    "        self.patience = patience\n",
    "        self.mode = mode\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.best_prev_score = np.Inf if mode == 'min' else -np.Inf\n",
    "        self.delta = delta\n",
    "        self.save_path = save_path\n",
    "        self.metric_name = 'metric' if not metric_name else metric_name\n",
    "        if save_format not in ['torch', 'tf']:\n",
    "            raise ValueError('Expected to save in one of the following formats: [\"torch\", \"tf\"]')\n",
    "        self.save_format = save_format\n",
    "        \n",
    "    def __call__(self, metric_value, model):\n",
    "\n",
    "        score = -metric_value if self.mode == 'min' else metric_value\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(metric_value, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(\n",
    "                f'No imporvement in Validation {self.metric_name}. Current: {score:.6f}. Current best: {self.best_score:.6f}')\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(metric_value, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, metric_value, model):\n",
    "        \"\"\"Saves model when validation loss decrease.\"\"\"\n",
    "        if self.verbose:\n",
    "            print(\n",
    "                f'Validation {self.metric_name} improved ({self.best_prev_score:.6f} --> {metric_value:.6f}).  Saving model ...')\n",
    "        if self.save_format == 'tf':\n",
    "            model.save_weights(self.save_path)\n",
    "        else:\n",
    "            torch.save(model.state_dict(), self.save_path)\n",
    "            \n",
    "        self.best_prev_score = metric_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2848cd90",
   "metadata": {
    "papermill": {
     "duration": 0.008542,
     "end_time": "2022-08-01T18:31:13.946932",
     "exception": false,
     "start_time": "2022-08-01T18:31:13.938390",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## TF-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d62a2583",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T18:31:13.965748Z",
     "iopub.status.busy": "2022-08-01T18:31:13.964884Z",
     "iopub.status.idle": "2022-08-01T18:31:14.030376Z",
     "shell.execute_reply": "2022-08-01T18:31:14.029518Z"
    },
    "papermill": {
     "duration": 0.077288,
     "end_time": "2022-08-01T18:31:14.032689",
     "exception": false,
     "start_time": "2022-08-01T18:31:13.955401",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, dataset_train, batch_size=64, shuffle=True, cur_epoch=0,\n",
    "                steps_per_epoch=5000, callbacks=None):\n",
    "    \"\"\"\n",
    "    функция обучения модели одну эпоху\n",
    "    :param model: tf.keras.Model\n",
    "    :param dataset_train: путь до директории с последовательностями\n",
    "    :param batch_size: размер батча\n",
    "    :param shuffle: флаг, если True, то перемешивает данные\n",
    "    :param cur_epoch:\n",
    "    :param steps_per_epoch:\n",
    "    :param callbacks: cписок из tf.keras.callbacks или None\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    train_generator = batches_generator(dataset_train, batch_size=batch_size, shuffle=shuffle,\n",
    "                                        output_format='tf', is_train=True)\n",
    "    model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=cur_epoch + 1,\n",
    "              initial_epoch=cur_epoch, callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d35faaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T18:31:14.051236Z",
     "iopub.status.busy": "2022-08-01T18:31:14.050949Z",
     "iopub.status.idle": "2022-08-01T18:31:14.116022Z",
     "shell.execute_reply": "2022-08-01T18:31:14.115178Z"
    },
    "papermill": {
     "duration": 0.076796,
     "end_time": "2022-08-01T18:31:14.118148",
     "exception": false,
     "start_time": "2022-08-01T18:31:14.041352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval_model(model, dataset_val, batch_size=32) -> float:\n",
    "    \"\"\"\n",
    "    функция для оценки качества модели на отложенной выборке, возвращает roc-auc на валидационной\n",
    "    выборке\n",
    "    :param model: tf.keras.Model\n",
    "    :param dataset_val: путь до директории с последовательностями\n",
    "    :param batch_size: размер батча\n",
    "    :return: val roc-auc score\n",
    "    \"\"\"\n",
    "    val_generator = batches_generator(dataset_val, batch_size=batch_size, shuffle=False,\n",
    "                                      output_format='tf', is_train=True)\n",
    "    preds = model.predict(val_generator).flatten()\n",
    "    val_generator = batches_generator(dataset_val, batch_size=batch_size, shuffle=False,\n",
    "                                      output_format='tf', is_train=True)\n",
    "    targets = []\n",
    "    for _, y in val_generator:\n",
    "        targets.extend(y)\n",
    "\n",
    "    return roc_auc_score(targets, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71d39fe9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T18:31:14.136777Z",
     "iopub.status.busy": "2022-08-01T18:31:14.136466Z",
     "iopub.status.idle": "2022-08-01T18:31:14.201626Z",
     "shell.execute_reply": "2022-08-01T18:31:14.200784Z"
    },
    "papermill": {
     "duration": 0.076982,
     "end_time": "2022-08-01T18:31:14.203899",
     "exception": false,
     "start_time": "2022-08-01T18:31:14.126917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inference(model, dataset_test, batch_size=32) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    функция, которая делает предикты на новых данных, возвращает pd.DataFrame из двух колонок:\n",
    "    (app_id, score)\n",
    "    :param model: tf.keras.Model\n",
    "    :param dataset_test: путь до директории с последовательностями\n",
    "    :param batch_size: размер батча\n",
    "    :return: pd.DataFrame из двух колонок: (app_id, score)\n",
    "    \"\"\"\n",
    "    app_ids = []\n",
    "    test_generator = batches_generator(dataset_test, batch_size=batch_size, shuffle=False,\n",
    "                                       is_train=False, output_format='tf')\n",
    "    \n",
    "    preds = model.predict(test_generator).flatten()\n",
    "    \n",
    "    app_ids = []\n",
    "    test_generator = batches_generator(dataset_test, batch_size=batch_size, shuffle=False, \n",
    "                                       is_train=False, output_format='tf')\n",
    "    for _, y in test_generator:\n",
    "        app_ids.extend(y)\n",
    "        \n",
    "    return pd.DataFrame({\n",
    "        'app_id': app_ids,\n",
    "        'score': preds\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5cda00ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T18:31:14.222294Z",
     "iopub.status.busy": "2022-08-01T18:31:14.222015Z",
     "iopub.status.idle": "2022-08-01T18:31:14.416681Z",
     "shell.execute_reply": "2022-08-01T18:31:14.415494Z"
    },
    "papermill": {
     "duration": 0.208494,
     "end_time": "2022-08-01T18:31:14.421089",
     "exception": false,
     "start_time": "2022-08-01T18:31:14.212595",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('../input/alfabattle2-sandbox/constants_for_rnn/constants_for_rnn/embedding_projections.pkl', 'rb') as f:\n",
    "    embedding_projections = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76df31bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T18:31:14.455275Z",
     "iopub.status.busy": "2022-08-01T18:31:14.454749Z",
     "iopub.status.idle": "2022-08-01T18:31:14.559579Z",
     "shell.execute_reply": "2022-08-01T18:31:14.558376Z"
    },
    "papermill": {
     "duration": 0.127384,
     "end_time": "2022-08-01T18:31:14.562172",
     "exception": false,
     "start_time": "2022-08-01T18:31:14.434788",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transactions_rnn(transactions_cat_features, embedding_projections, product_col_name='product', \n",
    "                          rnn_units=128, classifier_units=32, optimizer=None):\n",
    "    if not optimizer:\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "        \n",
    "    inputs = []\n",
    "    cat_embeds = []\n",
    "    \n",
    "    for feature_name in transactions_cat_features:\n",
    "        inp = L.Input(shape=(None, ), dtype='uint32', name=f'input_{feature_name}')\n",
    "        inputs.append(inp)\n",
    "        source_size, projection = embedding_projections[feature_name]\n",
    "        emb = L.Embedding(source_size+1, projection, trainable=True, mask_zero=False, name=f'embedding_{feature_name}')(inp)\n",
    "        cat_embeds.append(emb)\n",
    "    \n",
    "    # product feature\n",
    "    inp = L.Input(shape=(1, ), dtype='uint32', name=f'input_product')\n",
    "    inputs.append(inp)\n",
    "    source_size, projection = embedding_projections['product']\n",
    "    product_emb = L.Embedding(source_size+1, projection, trainable=True, mask_zero=False, name=f'embedding_product')(inp)\n",
    "    product_emb_reshape = L.Reshape((projection, ))(product_emb)\n",
    "    \n",
    "    concated_cat_embeds = L.concatenate(cat_embeds)\n",
    "    \n",
    "    last_state = L.GRU(units=rnn_units)(concated_cat_embeds)\n",
    "    \n",
    "    combined_inp = L.concatenate([last_state, product_emb_reshape])\n",
    "    \n",
    "    dense_intermediate = L.Dense(classifier_units, activation='relu', )(combined_inp)\n",
    "    proba = L.Dense(1, activation='sigmoid')(dense_intermediate)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=proba)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b95e9ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T18:31:14.589444Z",
     "iopub.status.busy": "2022-08-01T18:31:14.588897Z",
     "iopub.status.idle": "2022-08-01T18:31:14.691747Z",
     "shell.execute_reply": "2022-08-01T18:31:14.690791Z"
    },
    "papermill": {
     "duration": 0.119259,
     "end_time": "2022-08-01T18:31:14.694175",
     "exception": false,
     "start_time": "2022-08-01T18:31:14.574916",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bigru_pooling_model(transactions_cat_features, embedding_projections, product_col_name='product', \n",
    "                          rnn_units=128, classifier_units=32, optimizer=None):\n",
    "    if not optimizer:\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "        \n",
    "    inputs = []\n",
    "    cat_embeds = []\n",
    "    \n",
    "    for feature_name in transactions_cat_features:\n",
    "        inp = L.Input(shape=(None, ), dtype='uint32', name=f'input_{feature_name}')\n",
    "        inputs.append(inp)\n",
    "        source_size, projection = embedding_projections[feature_name]\n",
    "        emb = L.Embedding(source_size+1, projection, trainable=True, mask_zero=False, name=f'embedding_{feature_name}')(inp)\n",
    "        emb_dropout = L.Dropout(0.5)(emb)\n",
    "        cat_embeds.append(emb_dropout)\n",
    "    \n",
    "    # product feature\n",
    "    inp = L.Input(shape=(1, ), dtype='uint32', name=f'input_product')\n",
    "    inputs.append(inp)\n",
    "    source_size, projection = embedding_projections['product']\n",
    "    product_emb = L.Embedding(source_size+1, projection, trainable=True, mask_zero=False, name=f'embedding_product')(inp)\n",
    "    product_emb_reshape = L.Reshape((projection, ))(product_emb)\n",
    "    \n",
    "    concated_cat_embeds = L.concatenate(cat_embeds)\n",
    "    dropout_embeds = L.SpatialDropout1D(0.05)(concated_cat_embeds)\n",
    "    \n",
    "    sequences = L.Bidirectional(L.GRU(units=rnn_units, return_sequences=True))(dropout_embeds)\n",
    "    \n",
    "    pooled_avg_sequences = L.GlobalAveragePooling1D()(sequences)\n",
    "    pooled_max_sequences = L.GlobalMaxPooling1D()(sequences)\n",
    "    \n",
    "    concated = L.concatenate([pooled_avg_sequences, pooled_max_sequences, product_emb_reshape])\n",
    "    \n",
    "    dense_intermediate = L.Dense(classifier_units, activation='relu', \n",
    "                                 kernel_regularizer=keras.regularizers.L1L2(1e-7, 1e-5))(concated)\n",
    "    \n",
    "    proba = L.Dense(1, activation='sigmoid')(dense_intermediate)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=proba)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe3802f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T18:31:14.720390Z",
     "iopub.status.busy": "2022-08-01T18:31:14.719530Z",
     "iopub.status.idle": "2022-08-01T18:31:14.821342Z",
     "shell.execute_reply": "2022-08-01T18:31:14.820415Z"
    },
    "papermill": {
     "duration": 0.117475,
     "end_time": "2022-08-01T18:31:14.823866",
     "exception": false,
     "start_time": "2022-08-01T18:31:14.706391",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bigru_cnn_crf_model(transactions_cat_features, embedding_projections, product_col_name='product', \n",
    "                          rnn_units=128, classifier_units=32, optimizer=None):\n",
    "    if not optimizer:\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "        \n",
    "    inputs = []\n",
    "    cat_embeds = []\n",
    "    \n",
    "    for feature_name in transactions_cat_features:\n",
    "        inp = L.Input(shape=(None, ), dtype='uint32', name=f'input_{feature_name}')\n",
    "        inputs.append(inp)\n",
    "        source_size, projection = embedding_projections[feature_name]\n",
    "        emb = L.Embedding(source_size+1, projection, trainable=True, mask_zero=False, name=f'embedding_{feature_name}')(inp)\n",
    "        emb_dropout = L.Dropout(0.5)(emb)\n",
    "        conv = L.Convolution1D(kernel_size=3, filters=projection/2, padding='same',activation='relu', strides=1)(emb_dropout)\n",
    "        cat_embeds.append(conv)\n",
    "    \n",
    "    # product feature\n",
    "    inp = L.Input(shape=(1, ), dtype='uint32', name=f'input_product')\n",
    "    inputs.append(inp)\n",
    "    source_size, projection = embedding_projections['product']\n",
    "    product_emb = L.Embedding(source_size+1, projection, trainable=True, mask_zero=False, name=f'embedding_product')(inp)\n",
    "    product_emb_reshape = L.Reshape((projection, ))(product_emb)\n",
    "    \n",
    "    concated_cat_embeds = L.concatenate(cat_embeds)\n",
    "    dropout_embeds = L.SpatialDropout1D(0.05)(concated_cat_embeds)\n",
    "    \n",
    "    sequences = L.Bidirectional(L.GRU(units=rnn_units, return_sequences=True))(dropout_embeds)\n",
    "    \n",
    "    pooled_avg_sequences = L.GlobalAveragePooling1D()(sequences)\n",
    "    pooled_max_sequences = L.GlobalMaxPooling1D()(sequences)\n",
    "    \n",
    "    concated = L.concatenate([pooled_avg_sequences, pooled_max_sequences, product_emb_reshape])\n",
    "    \n",
    "    dense_intermediate = L.Dense(classifier_units, activation='relu', \n",
    "                                 kernel_regularizer=keras.regularizers.L1L2(1e-7, 1e-5))(concated)\n",
    "    \n",
    "    proba = L.Dense(1, activation='sigmoid')(dense_intermediate)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=proba)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a29687",
   "metadata": {
    "papermill": {
     "duration": 0.011926,
     "end_time": "2022-08-01T18:31:14.848151",
     "exception": false,
     "start_time": "2022-08-01T18:31:14.836225",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e985ca02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T18:31:14.873183Z",
     "iopub.status.busy": "2022-08-01T18:31:14.872781Z",
     "iopub.status.idle": "2022-08-01T18:31:17.581948Z",
     "shell.execute_reply": "2022-08-01T18:31:17.580730Z"
    },
    "papermill": {
     "duration": 2.724618,
     "end_time": "2022-08-01T18:31:17.584857",
     "exception": false,
     "start_time": "2022-08-01T18:31:14.860239",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove './rnn_baseline/checkpoints/pytorch_baseline': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "! mkdir ./rnn_baseline\n",
    "\n",
    "! mkdir ./rnn_baseline/checkpoints\n",
    "\n",
    "! rm -r ./rnn_baseline/checkpoints/pytorch_baseline\n",
    "! mkdir ./rnn_baseline/checkpoints/pytorch_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10cbd09c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T18:31:17.604316Z",
     "iopub.status.busy": "2022-08-01T18:31:17.603617Z",
     "iopub.status.idle": "2022-08-01T18:31:17.675978Z",
     "shell.execute_reply": "2022-08-01T18:31:17.675085Z"
    },
    "papermill": {
     "duration": 0.084377,
     "end_time": "2022-08-01T18:31:17.678277",
     "exception": false,
     "start_time": "2022-08-01T18:31:17.593900",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_to_checkpoints = './rnn_baseline/checkpoints/pytorch_baseline/'\n",
    "es = EarlyStopping(patience=3, mode='max', verbose=True, save_path=os.path.join(path_to_checkpoints, 'best_checkpoint.pt'), \n",
    "                   metric_name='ROC-AUC', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "248b1984",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T18:31:17.697712Z",
     "iopub.status.busy": "2022-08-01T18:31:17.696825Z",
     "iopub.status.idle": "2022-08-01T18:31:17.759857Z",
     "shell.execute_reply": "2022-08-01T18:31:17.758994Z"
    },
    "papermill": {
     "duration": 0.075025,
     "end_time": "2022-08-01T18:31:17.762171",
     "exception": false,
     "start_time": "2022-08-01T18:31:17.687146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "train_batch_size = 128\n",
    "val_batch_szie = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5cd4901",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T18:31:17.781198Z",
     "iopub.status.busy": "2022-08-01T18:31:17.780908Z",
     "iopub.status.idle": "2022-08-01T18:31:23.793486Z",
     "shell.execute_reply": "2022-08-01T18:31:23.792532Z"
    },
    "papermill": {
     "duration": 6.024725,
     "end_time": "2022-08-01T18:31:23.796080",
     "exception": false,
     "start_time": "2022-08-01T18:31:17.771355",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-01 18:31:17.880115: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-01 18:31:17.881454: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-01 18:31:17.882135: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-01 18:31:17.883044: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-01 18:31:17.883372: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-01 18:31:17.884287: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-01 18:31:17.885059: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-01 18:31:22.796305: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-01 18:31:22.797200: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-01 18:31:22.797872: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-01 18:31:22.798439: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15047 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    }
   ],
   "source": [
    "model = bigru_pooling_model(transaction_features, embedding_projections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c746783",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T18:31:23.816584Z",
     "iopub.status.busy": "2022-08-01T18:31:23.815809Z",
     "iopub.status.idle": "2022-08-01T18:31:23.888702Z",
     "shell.execute_reply": "2022-08-01T18:31:23.887657Z"
    },
    "papermill": {
     "duration": 0.087416,
     "end_time": "2022-08-01T18:31:23.892669",
     "exception": false,
     "start_time": "2022-08-01T18:31:23.805253",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_currency (InputLayer)     [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_operation_kind (InputLaye [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_card_type (InputLayer)    [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_operation_type (InputLaye [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_operation_type_group (Inp [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_ecommerce_flag (InputLaye [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_payment_system (InputLaye [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_income_flag (InputLayer)  [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_mcc (InputLayer)          [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_country (InputLayer)      [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_city (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_mcc_category (InputLayer) [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_day_of_week (InputLayer)  [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_hour (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_weekofyear (InputLayer)   [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_amnt (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_days_before (InputLayer)  [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_hour_diff (InputLayer)    [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_currency (Embedding)  (None, None, 6)      72          input_currency[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "embedding_operation_kind (Embed (None, None, 5)      40          input_operation_kind[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_card_type (Embedding) (None, None, 29)     5104        input_card_type[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_operation_type (Embed (None, None, 9)      207         input_operation_type[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_operation_type_group  (None, None, 3)      15          input_operation_type_group[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "embedding_ecommerce_flag (Embed (None, None, 3)      12          input_ecommerce_flag[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_payment_system (Embed (None, None, 5)      40          input_payment_system[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_income_flag (Embeddin (None, None, 3)      12          input_income_flag[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "embedding_mcc (Embedding)       (None, None, 22)     2398        input_mcc[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_country (Embedding)   (None, None, 9)      225         input_country[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "embedding_city (Embedding)      (None, None, 28)     4592        input_city[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_mcc_category (Embeddi (None, None, 10)     290         input_mcc_category[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_day_of_week (Embeddin (None, None, 5)      40          input_day_of_week[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "embedding_hour (Embedding)      (None, None, 9)      225         input_hour[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_weekofyear (Embedding (None, None, 15)     810         input_weekofyear[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "embedding_amnt (Embedding)      (None, None, 6)      66          input_amnt[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_days_before (Embeddin (None, None, 9)      216         input_days_before[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "embedding_hour_diff (Embedding) (None, None, 6)      66          input_hour_diff[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, None, 6)      0           embedding_currency[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, None, 5)      0           embedding_operation_kind[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, None, 29)     0           embedding_card_type[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, None, 9)      0           embedding_operation_type[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, None, 3)      0           embedding_operation_type_group[0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, None, 3)      0           embedding_ecommerce_flag[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, None, 5)      0           embedding_payment_system[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, None, 3)      0           embedding_income_flag[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, None, 22)     0           embedding_mcc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, None, 9)      0           embedding_country[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, None, 28)     0           embedding_city[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, None, 10)     0           embedding_mcc_category[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, None, 5)      0           embedding_day_of_week[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, None, 9)      0           embedding_hour[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, None, 15)     0           embedding_weekofyear[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, None, 6)      0           embedding_amnt[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, None, 9)      0           embedding_days_before[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, None, 6)      0           embedding_hour_diff[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, None, 182)    0           dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "                                                                 dropout_2[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "                                                                 dropout_4[0][0]                  \n",
      "                                                                 dropout_5[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "                                                                 dropout_7[0][0]                  \n",
      "                                                                 dropout_8[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "                                                                 dropout_10[0][0]                 \n",
      "                                                                 dropout_11[0][0]                 \n",
      "                                                                 dropout_12[0][0]                 \n",
      "                                                                 dropout_13[0][0]                 \n",
      "                                                                 dropout_14[0][0]                 \n",
      "                                                                 dropout_15[0][0]                 \n",
      "                                                                 dropout_16[0][0]                 \n",
      "                                                                 dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d (SpatialDropo (None, None, 182)    0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_product (InputLayer)      [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, None, 256)    239616      spatial_dropout1d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "embedding_product (Embedding)   (None, 1, 4)         24          input_product[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 256)          0           bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d (GlobalMax (None, 256)          0           bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 4)            0           embedding_product[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 516)          0           global_average_pooling1d[0][0]   \n",
      "                                                                 global_max_pooling1d[0][0]       \n",
      "                                                                 reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 32)           16544       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            33          dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 270,647\n",
      "Trainable params: 270,647\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "501f46bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T18:31:23.912977Z",
     "iopub.status.busy": "2022-08-01T18:31:23.912666Z",
     "iopub.status.idle": "2022-08-01T20:29:11.011280Z",
     "shell.execute_reply": "2022-08-01T20:29:11.009598Z"
    },
    "papermill": {
     "duration": 7069.34103,
     "end_time": "2022-08-01T20:29:13.243172",
     "exception": false,
     "start_time": "2022-08-01T18:31:23.902142",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-01 18:31:29.448990: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-08-01 18:31:35.265222: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7270/7270 [==============================] - 405s 55ms/step - loss: 0.1090\n",
      "Validation ROC-AUC improved (-inf --> 0.770848).  Saving model ...\n",
      "Epoch 1 completed. Train roc-auc: 0.7732608456727383, Val roc-auc: 0.770848267050966\n",
      "Starting epoch 2\n",
      "Epoch 2/2\n",
      "7270/7270 [==============================] - 401s 55ms/step - loss: 0.1055\n",
      "Validation ROC-AUC improved (0.770848 --> 0.774590).  Saving model ...\n",
      "Epoch 2 completed. Train roc-auc: 0.7797877991978758, Val roc-auc: 0.7745895547089926\n",
      "Starting epoch 3\n",
      "Epoch 3/3\n",
      "7270/7270 [==============================] - 387s 53ms/step - loss: 0.1042\n",
      "Validation ROC-AUC improved (0.774590 --> 0.778001).  Saving model ...\n",
      "Epoch 3 completed. Train roc-auc: 0.790625304050266, Val roc-auc: 0.7780007603722701\n",
      "Starting epoch 4\n",
      "Epoch 4/4\n",
      "7270/7270 [==============================] - 378s 52ms/step - loss: 0.1033\n",
      "Validation ROC-AUC improved (0.778001 --> 0.780537).  Saving model ...\n",
      "Epoch 4 completed. Train roc-auc: 0.7962698959809478, Val roc-auc: 0.780537055526281\n",
      "Starting epoch 5\n",
      "Epoch 5/5\n",
      "7270/7270 [==============================] - 390s 54ms/step - loss: 0.1023\n",
      "No imporvement in Validation ROC-AUC. Current: 0.775662. Current best: 0.780537\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch 5 completed. Train roc-auc: 0.7997916258372664, Val roc-auc: 0.775662277070098\n",
      "Starting epoch 6\n",
      "Epoch 6/6\n",
      "7270/7270 [==============================] - 385s 53ms/step - loss: 0.1017\n",
      "Validation ROC-AUC improved (0.780537 --> 0.781353).  Saving model ...\n",
      "Epoch 6 completed. Train roc-auc: 0.8059446181176622, Val roc-auc: 0.7813525648680446\n",
      "Starting epoch 7\n",
      "Epoch 7/7\n",
      "7270/7270 [==============================] - 380s 52ms/step - loss: 0.1010\n",
      "No imporvement in Validation ROC-AUC. Current: 0.775993. Current best: 0.781353\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch 7 completed. Train roc-auc: 0.8068654934070015, Val roc-auc: 0.7759932536729637\n",
      "Starting epoch 8\n",
      "Epoch 8/8\n",
      "7270/7270 [==============================] - 387s 53ms/step - loss: 0.1005\n",
      "No imporvement in Validation ROC-AUC. Current: 0.779067. Current best: 0.781353\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Epoch 8 completed. Train roc-auc: 0.8098782687597229, Val roc-auc: 0.7790669263310339\n",
      "Starting epoch 9\n",
      "Epoch 9/9\n",
      "7270/7270 [==============================] - 392s 54ms/step - loss: 0.1003\n",
      "No imporvement in Validation ROC-AUC. Current: 0.776272. Current best: 0.781353\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping reached. Stop training...\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print(f'Starting epoch {epoch+1}')\n",
    "    train_epoch(model, dataset_train, batch_size=train_batch_size, shuffle=True, cur_epoch=epoch, \n",
    "                steps_per_epoch=7270)\n",
    "    \n",
    "    val_roc_auc = eval_model(model, dataset_val, batch_size=val_batch_szie)\n",
    "    model.save_weights(os.path.join(path_to_checkpoints, f'epoch_{epoch+1}_val_{val_roc_auc:.3f}.hdf5'))\n",
    "    \n",
    "    es(val_roc_auc, model)\n",
    "    \n",
    "    if es.early_stop:\n",
    "        print('Early stopping reached. Stop training...')\n",
    "        break\n",
    "        \n",
    "    train_roc_auc = eval_model(model, dataset_train, batch_size=val_batch_szie)\n",
    "    print(f'Epoch {epoch+1} completed. Train roc-auc: {train_roc_auc}, Val roc-auc: {val_roc_auc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7104.538121,
   "end_time": "2022-08-01T20:29:19.014231",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-08-01T18:30:54.476110",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
